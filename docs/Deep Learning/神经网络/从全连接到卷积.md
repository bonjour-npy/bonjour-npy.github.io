# 从全连接到卷积

## I.卷积的诞生&核心特征

1. 现代图片具有较大的像素，使用全连接层导致参数爆炸
2. 针对图片的特征提取和模式识别，应具备以下原则：
   - 平移不变性
   - 局部性

## II.重新考察全连接层

1. 将全连接层的一维输入和输出变换为二维的矩阵，公式如下

   其中$i,j$代表输出神经元的二维索引坐标，$h,w$代表输入神经元的二维索引坐标

$$
y_{i,j}=\sum_{h,w}{w_{i,j,h,w}*x_{h,w}} \tag{1}
$$
2. 进一步将权重以及输入的索引变形，公式如下

   其中$a,b$的取值可负可正，直到遍历所有权重以及输入神经元，实现全连接

$$
y_{i,j}=\sum_{h,w}{w_{i,j,h,w}*x_{h,w}}=\sum_{a,b}{v_{i,j,a,b}*x_{i+a,j+b}} \tag{2}
$$

3. 在公式(2)中，当$i,j$发生变化时，即产生平移，权重也发生平移，不满足平移不变性。

   为了解决这一问题，将公式(2)变形为如下

   此时参数权值共享，满足了平移不变性
   $$
   y_{i,j}=\sum_{a,b}{v_{i,j,a,b}*x_{i+a,j+b}}=\sum_{a,b}{v_{a,b}*x_{i+a,j+b}} \tag{3}
   $$

4. 

4. 再考虑局部性，在进行特征提取以及模式识别时，只需关注周围的局部特征，因此公式(3)中的$a,b$可缩小范围，并不用来实现全连接，此时$a,b$代表着卷积核的感受野，即kernel size
5. 此时完成了全连接层到卷积层的转换

## III. 总结

对全连接层使用平移不变性和局部性得到卷积层，卷积是特殊的全连接
$$
y_{i,j}=\sum_{a,b}{v_{a,b}*x_{i+a,j+b}}=\sum_{a=-\Delta}^{\Delta}\sum_{b=-\Delta}^{\Delta}{v_{a,b}*x_{i_a,j+b}} \tag{4}
$$




