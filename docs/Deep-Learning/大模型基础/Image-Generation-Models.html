<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Deep-Learning/大模型基础/Image-Generation-Models" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">图像生成模型 | 培洋的笔记本📒</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://bonjour-npy.github.io/./static/img/intro.png"><meta data-rh="true" name="twitter:image" content="https://bonjour-npy.github.io/./static/img/intro.png"><meta data-rh="true" property="og:url" content="https://bonjour-npy.github.io/docs/Deep-Learning/大模型基础/Image-Generation-Models"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="图像生成模型 | 培洋的笔记本📒"><meta data-rh="true" name="description" content="回顾文字生成的两种方法"><meta data-rh="true" property="og:description" content="回顾文字生成的两种方法"><link data-rh="true" rel="icon" href="/img/rockstar-games.svg"><link data-rh="true" rel="canonical" href="https://bonjour-npy.github.io/docs/Deep-Learning/大模型基础/Image-Generation-Models"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/en/docs/Deep-Learning/大模型基础/Image-Generation-Models" hreflang="en"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Deep-Learning/大模型基础/Image-Generation-Models" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Deep-Learning/大模型基础/Image-Generation-Models" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.2503678d.css">
<script src="/assets/js/runtime~main.275f8aea.js" defer="defer"></script>
<script src="/assets/js/main.5b1713e6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const a=new URLSearchParams(window.location.search).entries();for(var[t,e]of a)if(t.startsWith("docusaurus-data-")){var n=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(n,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><div class="announcementBar_mb4j" role="banner"><div class="content_knG7 announcementBarContent_xLdY">✨ 求实求真，大气大为 ✨</div></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/navbar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/navbar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">培洋的笔记本</b></a><a class="navbar__item navbar__link" href="/docs/Deep-Learning/intro">🤖 深度学习</a><a class="navbar__item navbar__link" href="/docs/GPU-Server/intro">🌍 服务器使用</a><a class="navbar__item navbar__link" href="/docs/Tui-Mian/intro">🤡 推免</a><a class="navbar__item navbar__link" href="/docs/Algorithms/intro">🎰 算法</a><a class="navbar__item navbar__link" href="/docs/Curriculum/intro">📖 课程学习</a><a class="navbar__item navbar__link" href="/docs/Others/intro">☃️ 其他</a><a class="navbar__item navbar__link" href="/docs/Acknowledgement/intro">🍺 饮水思源</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Deep-Learning/intro">Welcome</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Deep-Learning/Fill-The-Gaps">查漏补缺</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Deep-Learning/基础知识/AlexNet">基础知识</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Deep-Learning/代码实现/Visdom-Visualization">代码实现</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/Deep-Learning/大模型基础/Self-Attention">大模型基础</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Self-Attention">自注意力（Self-Attention）</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Attention-Is-All-You-Need">NeurIPS 2017: Attention Is All You Need</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Self-Supervised-Learning">自监督学习（Self-Supervised Learning）</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Deep-Learning/大模型基础/Image-Generation-Models">图像生成模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/GAN">生成式对抗网络（GAN）</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Diffusion-Model">扩散模型（Diffusion Model）</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Sampling-for-Generation">生成模型中的采样技 巧</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation">Prompt Learning</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Deep-Learning/生成模型总结/Quick-Notes-about-Main-Techs">生成模型总结</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Deep-Learning/论文笔记/Attention-Is-All-You-Need">论文笔记</a></div></li></ul></nav><button type="button" title="收起侧边栏" aria-label="收起侧边栏" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">大模型基础</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">图像生成模型</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>图像生成模型</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="回顾文字生成的两种方法">回顾文字生成的两种方法<a href="#回顾文字生成的两种方法" class="hash-link" aria-label="回顾文字生成的两种方法的直接链接" title="回顾文字生成的两种方法的直接链接">​</a></h2>
<p>在文字生成模型中根据模型的输入是否与前一时刻的输出有关可以分为自回归AR模型与非自回归NAR模型两种，这两种生成方式的利与弊在图像生成中仍然存在。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="自回归方法ar">自回归方法（AR）<a href="#自回归方法ar" class="hash-link" aria-label="自回归方法（AR）的直 接链接" title="自回归方法（AR）的直接链接">​</a></h3>
<p>Transformer-based的文字生成模型有很多，如GPT模型，大多使用自回归（Autoregressive, abbr. AR）的方法逐token生成。</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>什么是ARM</div><div class="admonitionContent_BuS1"><p>ARM（Autoregressive Model，自回归模型）是一类用于建模时间序列数据的统计模型，其中当前时刻的观测值被认为是过去时刻观测值的线性组合，加上一个随机误差项。这类模型的核心思想是，当前时刻的数据依赖于先前时刻的数据。</p></div></div>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231125212727371.png" alt="image-20231125212727371" class="img_ev3q"></p>
<p>若把文字生成的AR方法对应到图像生成中的使用，即一个一个像素生成图像。由于当前对高清图像像素的需求越来越高，自回归的生成方式导致速度非常缓慢，但优点是后面生成的每一个像素都考虑了之前的所有像素，从而使生成的图像更清晰、更细腻、更加符合预期。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="非自回归方法nar">非自回归方法（NAR）<a href="#非自回归方法nar" class="hash-link" aria-label="非自回归方法（NAR  ）的直接链接" title="非自回归方法（NAR）的直接链接">​</a></h3>
<p>若使用NAR非自回归的方法一次生成所有像素，各像素在生成时无法考虑之间的语义信息，生成的图像质量普遍低于自回归方法生成的图像。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127103421435.png" alt="image-20231127103421435" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="目前图像生成模型的共同点">目前图像生成模型的共同点<a href="#目前图像生成模型的共同点" class="hash-link" aria-label="目前图像生成模型的共同点的直接链接" title="目前图像生成模型的共同点的直接链接">​</a></h3>
<p>VAE、GAN以及Diffusion Model等生成模型，都不只是单独使用文字作为输入来生成图像，而是使用了<strong>从已知的随机分布（e.g. Normal Distribution）中sample出向量作为模型额外输入</strong>的方法。</p>
<p>大致的思想如下图所示，由于<strong>期待生成的图像并不是固定的</strong>，可以将预期输出看作是一个分布，即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">∣</mi><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(x|y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span>，而图像生成模型需要完成的任务就是将输入的从某一随机分布中sample出的向量对应到图像预期输出分布中的某一个图像。</p>
<div class="theme-admonition theme-admonition-important admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>important</div><div class="admonitionContent_BuS1"><p>总结：由于根据文字prompt期待生成的图像并不是固定的，可以认为生成的图片在目标域（Target Domain）符合某种分布。因此目前的SOTA模型除了将文字Prompt作为输入，还从某随机分布中sample出图片shape的随机向量（矩阵）作为输入，期待模型根据prompt将源域（Source Domain）输入的随机向量映射到目标域的分布，生成对应的图片。</p></div></div>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127104041455.png" alt="image-20231127104041455" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="生成模型的共同结构">生成模型的共同结构<a href="#生成模型的共同结构" class="hash-link" aria-label="生成模型的共同结构的直接链接" title="生成模型的共同结构的直接链接">​</a></h2>
<p>Stable Diffusion是目前图像生成的SOTA模型之一，在本章中我们快速的了解一下Stable Diffusion的大致框架以及原理。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="通用框架概览">通用框架概览<a href="#通用框架概览" class="hash-link" aria-label="通用框架概览的直接链接" title="通用框架概览的直接链接">​</a></h3>
<p>目前，如Stable Diffusion等SOTA图像生成模型都具备以下所示的三个模块，通常情况下这三个模块分开训练，最终通过特殊的逻辑和规则组合在一起。</p>
<ul>
<li>Text Encoder：根据输入的text prompt进行嵌入表示</li>
<li>Generation Model：接受Text Encoder输出的prompt表示以及从随机分布sample出的图像大小的向量，得到“中间产物”，中间产物有以下两种情况：
<ol>
<li><strong>具有视觉意义但经过压缩比较模糊的图像</strong></li>
<li><strong>不具备视觉特征的矩阵（Latent Representation）</strong></li>
</ol>
</li>
<li>Decoder：以上述的“中间产物”作为输入，生成出高清图像</li>
</ul>
<p>通用框架的三个组成部分如下图所示：</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127173905238.png" alt="image-20231127173905238" class="img_ev3q"></p>
<p>再附上Stable Diffusion、DALL-E系列以及Google的Imagen的结构说明。</p>
<p>其中Imagen将压缩版本的图片作为Generation Model的中间产物，Stable Diffusion以及DALL-E将Latent Representation作为中间产物。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127195336960.png" alt="image-20231127195336960" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127195527792.png" alt="image-20231127195527792" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127200044147.png" alt="img" class="img_ev3q"></p>
<p>根据Imagen的实验结果，相对于Decoder即Diffusion Model的模型大小，Text Encoder的模型大小对图像生成模型的影响是非常大的。Text Encoder可以帮助模型理解prompt中在训练资料的文字-图像对中没有出现的新的词汇，从而提高图像生成的表现。</p>
<blockquote>
<p>Scaling text encoder size is more important than U-Net size. While scaling the size of the diffusion model U-Net improves sample quality, we found scaling the text encoder size to be significantly more impactful than the U-Net size.</p>
<p><a href="https://arxiv.org/pdf/2205.11487.pdf" target="_blank" rel="noopener noreferrer">Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</a></p>
</blockquote>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127201338956.png" alt="image-20231127201338956" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark">Benchmark<a href="#benchmark" class="hash-link" aria-label="Benchmark的直接链接" title="Benchmark的直接链接">​</a></h3>
<p>下面介绍两种用于评估图像生成模型的常用Benchmark：FID与CLIP Score。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="fidfréchet-inception-distance">FID（Fréchet Inception Distance）<a href="#fidfréchet-inception-distance" class="hash-link" aria-label="FID（Fréchet Inception Distance）的直接链接" title="FID（Fréchet Inception Distance）的直接链接">​</a></h4>
<p>FID提供一个Pre-trained的CNN，该CNN通常使用预训练的Inception v3模型。在计算FID时，生成图像和真实图像分别输入到预训练的CNN中，提取出各自的特征表示向量（Representation）。这两个Representation越接近，代表输出的图像越像预期的“真实”图片。</p>
<p>在FID中，做出了如下重要的假设**：将生成的图像真实的图像经过CNN输出的Representation看作是sample自两个高斯分布的随机变量**。然后，通过计算两个特征向量的均值和协方差矩阵来得到两个高斯分布的参数。最后，利用两个高斯分布之间的Fréchet距离来衡量生成图像与真实图像之间的差异。</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mrow><mi mathvariant="normal">F</mi><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mo>=</mo><msubsup><mrow><mo fence="true">∥</mo><msub><mi>μ</mi><mn>1</mn></msub><mo>−</mo><msub><mi>μ</mi><mn>2</mn></msub><mo fence="true">∥</mo></mrow><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mrow><mi mathvariant="normal">t</mi><mi mathvariant="normal">r</mi></mrow><mrow><mo fence="true">(</mo><msub><mi mathvariant="normal">Σ</mi><mn>1</mn></msub><mo>+</mo><msub><mi mathvariant="normal">Σ</mi><mn>2</mn></msub><mo>−</mo><mn>2</mn><msup><mrow><mo fence="true">(</mo><msub><mi mathvariant="normal">Σ</mi><mn>1</mn></msub><msub><mi mathvariant="normal">Σ</mi><mn>2</mn></msub><mo fence="true">)</mo></mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></msup><mo fence="true">)</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(1)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathrm{FID}=\left\|\mu_1-\mu_2\right\|_2^2+\mathrm{tr}\left(\Sigma_1+\Sigma_2-2\left(\Sigma_1\Sigma_2\right)^{\frac12}\right)\tag{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathrm">FID</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2537em;vertical-align:-0.2997em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em">∥</span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">∥</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em"><span style="top:-2.4003em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em"></span><span class="mord"><span class="mord mathrm">tr</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0939em"><span style="top:-3.5029em;margin-right:0.05em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.384em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">)</span></span></span></span><span class="tag"><span class="strut" style="height:1.8em;vertical-align:-0.65em"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mu_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>μ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mu_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>分别是第一个和第二个高斯分布的均值向量；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Σ</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\Sigma_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Σ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\Sigma_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>则是它们的协方差矩阵；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">t</mi><mi mathvariant="normal">r</mi></mrow><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{tr}(\cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathrm">tr</span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span>表示矩阵的迹运算。</p>
<p>高斯分布的均值向量从观测到的数据中计算出来的。对于一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>-维高斯分布，其均值向量可以表示为一个长度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>的列向量，其中的每一个元素都是一个特定维度的平均数，这可以通过在每个维度上进行简单的算术平均来完成。</p>
<p>值得注意的是，FID指标需要一定数量的生成图像和真实图像来进行统计估计。这是因为FID的计算是基于两个高斯分布之间的距离计算的，因此需  要足够多的样本数量才能够获得较为准确的概率分布估计。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127202031894.png" alt="image-20231127202031894" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="clip-score">CLIP Score<a href="#clip-score" class="hash-link" aria-label="CLIP Score的直接链接" title="CLIP Score的直接链接">​</a></h4>
<p>CLIP Score中的CLIP指的就是<a href="https://arxiv.org/abs/2103.00020" target="_blank" rel="noopener noreferrer">OpenAI的CLIP（Contrastive Language-Image Pre-Training）模型</a>。</p>
<p>具体来说，CLIP Score的计算方式是将用于生成图像的文字prompt输入至CLIP的Text Encoder中得到一个Representation，再将对应prompt生成的图像输入至CLIP的Image Encoder中得到对应的Representation，计算二者之间的距离，即得到CLIP Score。分数越小，代表文字和图像更align。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231128143336879.png" alt="image-20231128143336879" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="通用框架解析">通用框架解析<a href="#通用框架解析" class="hash-link" aria-label="通用框架解析的直接链接" title="通用框架解析的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="generation-model">Generation Model<a href="#generation-model" class="hash-link" aria-label="Generation Model的直接链接" title="Generation Model的直接链接">​</a></h4>
<p>Generation Model的生成过程其实就是Denoise的过程。具体来讲，输入文字Prompt以及从随机分布中sample出的与预期生成图像具有相同大小的噪声矩阵，预测出输入图片中的噪声分布，在输入图像中减去噪声，输出去噪后的图像。Generation Model的最终输出是中间产物，这个中间产物可以是图像的压缩版本，也可以是一个Latent Representation。因此，训练Generation Model其实就是训练一个<strong>Noise Predictor</strong>。</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="中间产物是压缩图像">中间产物是压缩图像<a href="#中间产物是压缩图像" class="hash-link" aria-label="中间产物是压缩图像的直接链接" title="中间产物是压缩图像的直接链接">​</a></h5>
<p>当Generation Model的中间产物是压缩图像时，如Diffusion模型，在训练Generation Model时的训练资料可以通过对数据集中的原始图片添加与图像大小一致地从已知随机分布中sample出的噪声来获得。此时加入噪声后的图像可以作为压缩图像输入至Noise Predictor中，而需要预测出的噪声分布的Ground Truth就是sample出的噪声。</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="中间产物是latent-representation">中间产物是Latent Representation<a href="#中间产物是latent-representation" class="hash-link" aria-label="中间产物是Latent Representation的直接链接" title="中间产物是Latent Representation的直接链接">​</a></h5>
<p>中间产物是Latent Representation时，同样采取从已知随机分布中sample出噪声再添加到网络的输入作为生成Ground Truth的策略，但是还<strong>额外需要一个Encoder来产生Latent Representation</strong>。</p>
<p>这里的Encoder使用数据集中的图片（即期待模型最终输出的图片）作为输入，输出该图片的某种Latent Representation，经过从随机分布中sample出的噪声的加入，输入至Noise Predictor中。从随机分布中sample出的噪声就是Noise Predictor的Ground Truth。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="decoder">Decoder<a href="#decoder" class="hash-link" aria-label="Decoder的直接链接" title="Decoder的直接链接">​</a></h4>
<p>Generation Model的训练需要大量成对的（Pair）文字-图像资料 。而对于Decoder来说，它的输入是中间产物（即Generation Model生成的压缩的图片或Latent Representation），输出的是还原出的高分辨率的图像，它的训练是<strong>不需要额外pair的文字-图像资料</strong>。</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="中间产物是压缩图像-1">中间产物是压缩图像<a href="#中间产物是压缩图像-1" class="hash-link" aria-label="中间产物是压缩图像的直接链接" title="中间产物是压缩图像的直接链接">​</a></h5>
<p>当Generation Model的输出是压缩版本的图像时，Decoder的训练资料可以将从互联网上fetch到的图像作为label，并对这些图像做Down Sampling来获得压缩版本的图像作为Decoder训练时的输出。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231128145010346.png" alt="image-20231128145010346" class="img_ev3q"></p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="中间产物是latent-representation-1">中间产物是Latent Representation<a href="#中间产物是latent-representation-1" class="hash-link" aria-label="中间产物是Latent Representation的直接链接" title="中间产物是Latent Representation的直接链接">​</a></h5>
<p>当中间产物是Latent Representation时，需要训练一个Auto-Encoder，使用Encoder-Decoder的结构训练生成模型的Decoder。</p>
<p>具体来讲，向Encoder中输入数据集中的高清预期图片，Encoder将其转换为某种Latent Representation，Decoder再吃Encoder的输出，最终输出还原出的高清label图片，训练的方向是让输出的图片与输入的图片越接近越好。<strong>在这个过程中，不需要额外的标注，Auto-Encoder和生成模型的Decoder一起更新参数。</strong></p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231128150641374.png" alt="image-20231128150641374" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="常见图像生成模型速览">常见图像生成模型速览<a href="#常见图像生成模型速览" class="hash-link" aria-label="常见图像生成模型速览的直接链接" title="常见图像生成模型速览的直接链接">​</a></h2>
<p>在这个模块大致介绍目前常见的几种图像生成模型，其中Diffusion Model以及GAN将在以后的文章中详细讲解。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="变分自编码器vae">变分自编码器（VAE）<a href="#变分自编码器vae" class="hash-link" aria-label="变分自编码器（VAE）的直接链接" title="变分自编码器（VAE）的直接链接">​</a></h3>
<p>变分自编码器（Variational Auto-Encoder, abbr. VAE）的训练策略是使用Encoder将输入图像对应（嵌入）到一个符合某随机分布的向量，再将该向量作为Decoder的输入，加上文字prompt后，期待模型产生合适的图像。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127104842038.png" alt="image-20231127104842038" class="img_ev3q"></p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>VAE在训练过程中，期待Ecoder输入多张图片后，  输出的向量在一起符合某个随机分布（e.g. Normal Distribution），并不是Encoder直接输出一个Distrubution。</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="基于流的生成模型flow-based-generative-model">基于流的生成模型（Flow-Based Generative Model）<a href="#基于流的生成模型flow-based-generative-model" class="hash-link" aria-label="基于流的生成模型（Flow-Based Generative Model）的直接链接" title="基于流的生成模型（Flow-Based Generative Model）的直接链接">​</a></h3>
<p>基于流的生成模型采用特殊的网络结构的设计，将Encoder设计为可逆的（invertible），在训练阶段喂入多张图片，期待模型的向量符合某个随机分布。而在预测阶段，由于Encoder是可逆的，输入从该随机分布中sample出来的向量，期待输出对应的图像。</p>
<p>注意，由于Encoder是可逆的，在训练阶段其输入的图片矩阵的形状应该等于输出的随机分布向量的形状，在推理阶段亦然。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127111749208.png" alt="image-20231127111749208" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="生成对抗网络gan">生成对抗网络（GAN）<a href="#生成对抗网络gan" class="hash-link" aria-label="生成对抗网络（GAN）的直接链接" title="生成对抗网络（GAN）的直接链接">​</a></h3>
<p>GAN模型的结构分为Generator和Discriminator，其中Generator接受来自随机分布的向量，产生预期图像；Discriminator接受生成器输出的图像或真实图像，输出输入的图像是真实图像的概率。在训练过程中，通过固定生成器参数来更新辨别器参数、固定辨别器参数更新生成器参数的往复交替训练来形成“两个网络对抗”的效果，从而使得生成器生成的图像更逼真（与输入的真实图像更近似）、辨别器识别是否是输入的真实图像的精确度更高。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127113242641.png" alt="image-20231127113242641" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="扩散模型diffusion-model">扩散模型（Diffusion Model）<a href="#扩散模型diffusion-model" class="hash-link" aria-label="扩散模型（Diffusion Model）的直接链接" title="扩散模型（Diffusion Model）的直接链接">​</a></h3>
<p>扩散模型的核心思想是对输入的图片加入噪声使其成为从某一随机分布sample出的向量，并在这个过程中训练出Noise Predictor；在生成图片时，输入从该随机分布中sample出的向量，使用训练出的Noise Predictor对噪声denoise从而获得生成的图片。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20231127112447752.png" alt="image-20231127112447752" class="img_ev3q"></p>
<p>以<a href="https://arxiv.org/abs/2006.11239" target="_blank" rel="noopener noreferrer">DDPM（Denoising Diffusion Probabilistic Models）</a>模型为例，模型在denoise时为每个denoise步骤赋予一个编号，越早进行denoise的步骤编号越大，因此，这个编号也代表着图像中噪声的严重程度。在Denoise模块中，模型根据输入的带有噪声的图片、文字prompt以及噪声的严重程度（即denoise的步骤）预测出该图片中噪声的分布，然后将输入的图片中减去预测出的噪声得到denoise后的图片。</p>
<p>Denoise模块的目标是预测出输入的噪声图片中的噪声，其资料可以通过对数据集中的图片不断加入从Gaussian Distribution中sample出的噪声的方法来获得，这个<strong>加噪声的过程我们称为Forward Process or Diffusion Process</strong>。此时将加入噪声后的图片、文字prompt以及denoise的步骤序号作为输入，sample出的噪声作为Ground Truth对noise predictor进行训练。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/bonjour-npy/bonjour-npy.github.io/tree/master/docs/Deep-Learning/5-大模型基础/4-Image-Generation-Models.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Deep-Learning/大模型基础/Self-Supervised-Learning"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">自监督学习（Self-Supervised Learning）</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Deep-Learning/大模型基础/GAN"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">生成式对抗网络（GAN）</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#回顾文字生成的两种方法" class="table-of-contents__link toc-highlight">回顾文字生成的两种方法</a><ul><li><a href="#自回归方法ar" class="table-of-contents__link toc-highlight">自回归方法（AR）</a></li><li><a href="#非自回归方法nar" class="table-of-contents__link toc-highlight">非自回归方法（NAR）</a></li><li><a href="#目前图像生成模型的共同点" class="table-of-contents__link toc-highlight">目前图像生成模型的共同点</a></li></ul></li><li><a href="#生成模型的共同结构" class="table-of-contents__link toc-highlight">生成模型的共同结构</a><ul><li><a href="#通用框架概览" class="table-of-contents__link toc-highlight">通用框架概览</a></li><li><a href="#benchmark" class="table-of-contents__link toc-highlight">Benchmark</a><ul><li><a href="#fidfréchet-inception-distance" class="table-of-contents__link toc-highlight">FID（Fréchet Inception Distance）</a></li><li><a href="#clip-score" class="table-of-contents__link toc-highlight">CLIP Score</a></li></ul></li><li><a href="#通用框架解析" class="table-of-contents__link toc-highlight">通用框架解析</a><ul><li><a href="#generation-model" class="table-of-contents__link toc-highlight">Generation Model</a><ul><li><a href="#中间产物是压缩图像" class="table-of-contents__link toc-highlight">中间产物是压缩图像</a></li><li><a href="#中间产物是latent-representation" class="table-of-contents__link toc-highlight">中间产物是Latent Representation</a></li></ul></li><li><a href="#decoder" class="table-of-contents__link toc-highlight">Decoder</a><ul><li><a href="#中间产物是压缩图像-1" class="table-of-contents__link toc-highlight">中间产物是压缩图像</a></li><li><a href="#中间产物是latent-representation-1" class="table-of-contents__link toc-highlight">中间产物是Latent Representation</a></li></ul></li></ul></li></ul></li><li><a href="#常见图像生成模型速览" class="table-of-contents__link toc-highlight">常见图像生成模型速览</a><ul><li><a href="#变分自编码器vae" class="table-of-contents__link toc-highlight">变分自编码器（VAE）</a></li><li><a href="#基于流的生成模型flow-based-generative-model" class="table-of-contents__link toc-highlight">基于流的生成模型（Flow-Based Generative Model）</a></li><li><a href="#生成对抗网络gan" class="table-of-contents__link toc-highlight">生成对抗网络（GAN）</a></li><li><a href="#  扩散模型diffusion-model" class="table-of-contents__link toc-highlight">扩散模型（Diffusion Model）</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">👋 联系我</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/WeChat_QR_Code.jpg" target="_blank" rel="noopener noreferrer" class="footer__link-item">WeChat<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.douyin.com/user/self?modal_id=7157246567970360614" target="_blank" rel="noopener noreferrer" class="footer__link-item">TikTok<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">✈️ 外部链接</div><ul class="footer__items clean-list"><li class="footer__item"><a href="http://www.mod.gov.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">共和国国防部<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.xuexi.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">学习强国<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://peacekeeping.un.org/zh" target="_blank" rel="noopener noreferrer" class="footer__link-item">联合国维持和平<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🎅 彩蛋</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.rockstargames.com/gta-v" target="_blank" rel="noopener noreferrer" class="footer__link-item">欢迎来到洛圣都<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.starwars.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">星球大战<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apple.com.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Apple(中国大陆)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🦄 教育官网</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.uestc.edu.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.guet.edu.cn" target="_blank" rel="noopener noreferrer" class="footer__link-item">桂林电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://cfm.uestc.edu.cn/index" target="_blank" rel="noopener noreferrer" class="footer__link-item">未来媒体研究中心<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><br>本网站所展示的标识、链接均属于个人创作和喜好表达，不代表任何国家、政府、企业或组织的官方立场或行为。<br>
                    尽管本网站努力确保信息的准确性和时效性，但所有信  息仅供参考，并不构成任何形式的法律、财务或商业建议。<br>
                    <br>Copyright © 2024 bonjour-npy. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>