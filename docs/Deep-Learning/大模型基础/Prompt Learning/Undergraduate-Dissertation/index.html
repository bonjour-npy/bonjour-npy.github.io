<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">本科毕业论文：基于 Prompt Learning 的视觉-语言大模型在图像生成中的应用与研究 | 培洋的笔记本📒</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://bonjour-npy.github.io/./static/img/intro.png"><meta data-rh="true" name="twitter:image" content="https://bonjour-npy.github.io/./static/img/intro.png"><meta data-rh="true" property="og:url" content="https://bonjour-npy.github.io/docs/Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="本科毕业论文：基于 Prompt Learning 的视觉-语言大模型在图像生成中的应用与研究 | 培洋的笔记本📒"><meta data-rh="true" name="description" content="本篇论文主要基于 IPL 的思想实现。本仓库大部分从 IPL-Zero-Shot-Generative-Model-Adaptation fork 而来并做出了一定修改。"><meta data-rh="true" property="og:description" content="本篇论文主要基于 IPL 的思想实现。本仓库大部分从 IPL-Zero-Shot-Generative-Model-Adaptation fork 而来并做出了一定修改。"><link data-rh="true" rel="icon" href="/img/rockstar-games.svg"><link data-rh="true" rel="canonical" href="https://bonjour-npy.github.io/docs/Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/en/docs/Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation" hreflang="en"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.0753ab9a.css">
<link rel="preload" href="/assets/js/runtime~main.ca8e12bd.js" as="script">
<link rel="preload" href="/assets/js/main.d56e5793.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><div class="announcementBar_mb4j" role="banner"><div class="content_knG7 announcementBarContent_xLdY">✨ 求实求真，大气大为 ✨</div></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/navbar.png" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/navbar.png" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">培洋的笔记本</b></a><a class="navbar__item navbar__link" href="/docs/Deep-Learning/intro">🤖 深度学习</a><a class="navbar__item navbar__link" href="/docs/Tui-Mian/intro">🤡 推免</a><a class="navbar__item navbar__link" href="/docs/Algorithms/intro">🎰 算法</a><a class="navbar__item navbar__link" href="/docs/Curriculum/intro">📖 课程学习</a><a class="navbar__item navbar__link" href="/docs/Others/intro">☃️ 其他</a><a class="navbar__item navbar__link" href="/docs/Acknowledgement/intro">🍺 饮水思源</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="搜索" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Deep-Learning/intro">Welcome</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Deep-Learning/Fill-The-Gaps">查漏补缺</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Deep-Learning/基础知识/AlexNet">基础知识</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Deep-Learning/实战练习/Visdom Visualization">实战练习</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/Deep-Learning/大模型基础/Self-Attention">大模型基础</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Self-Attention">自注意力（Self-Attention）</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Attention-Is-All-You-Need">NeurIPS 2017: Attention Is All You Need</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Self-Supervised-Learning">自监督学习（Self-Supervised Learning）</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Image-Generation-Models">图像生成模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/GAN">生成式对抗网络（GAN）</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Diffusion-Model">扩散模型（Diffusion Model）</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Deep-Learning/大模型基础/Sampling-for-Generation">生成模型中的采样技巧</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation">Prompt Learning</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Deep-Learning/大模型基础/Prompt Learning/Undergraduate-Dissertation">本科毕业论文：基于 Prompt Learning 的视觉-语言大模型在图像生成中的应用与研究</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Deep-Learning/论文笔记/Attention-Is-All-You-Need">论文笔记</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Deep-Learning/图像生成与视频生成大模型/Image-and-Video-Generative-Foundation-Model">图像生成与视频生成大模型</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/Deep-Learning/组会记录/1-20240705">组会记录</a></div></li></ul></nav><button type="button" title="收起侧边栏" aria-label="收起侧边栏" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">大模型基础</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Prompt Learning</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">本科毕业论文：基于 Prompt Learning 的视觉-语言大模型在图像生成中的应用与研究</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><h1>本科毕业论文：基于 Prompt Learning 的视觉-语言大模型在图像生成中的应用与研究</h1><p>本篇论文主要基于 <a href="https://arxiv.org/pdf/2304.03119.pdf" target="_blank" rel="noopener noreferrer">IPL</a> 的思想实现。本仓库大部分从 <a href="https://github.com/Picsart-AI-Research/IPL-Zero-Shot-Generative-Model-Adaptation" target="_blank" rel="noopener noreferrer">IPL-Zero-Shot-Generative-Model-Adaptation</a> fork 而来并做出了一定修改。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="依赖">依赖<a href="#依赖" class="hash-link" aria-label="依赖的直接链接" title="依赖的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="创建-anaconda-虚拟环境">创建 Anaconda 虚拟环境<a href="#创建-anaconda-虚拟环境" class="hash-link" aria-label="创建 Anaconda 虚拟环境的直接链接" title="创建 Anaconda 虚拟环境的直接链接">​</a></h3><div class="language-powershell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-powershell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">conda create -n ipl python=3.8</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda activate ipl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="安装依赖">安装依赖<a href="#安装依赖" class="hash-link" aria-label="安装依赖的直接链接" title="安装依赖的直接链接">​</a></h3><p>请确保 NVIDIA 驱动、CUDA 以及 PyTorch 之间版本互相匹配。</p><div class="language-powershell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-powershell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install ftfy regex tqdm ninja</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install git+https://github.com/openai/CLIP.git</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="下载预训练生成器">下载预训练生成器<a href="#下载预训练生成器" class="hash-link" aria-label="下载预训练生成器的直接链接" title="下载预训练生成器的直接链接">​</a></h3><p>预训练的源域生成器可以通过 <a href="https://drive.google.com/drive/folders/1FW8XfDbTg9MLEodEeIl6zJEaCVyZ053L?usp=sharing" target="_blank" rel="noopener noreferrer">Google Drive </a>或者 <a href="https://cloud.tsinghua.edu.cn/d/dbd0955d9a9547dc99f2/" target="_blank" rel="noopener noreferrer">Tsinghua Cloud</a> 下载，并将其置于 <code>./pre_stylegan</code> 文件夹中。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="概述">概述<a href="#概述" class="hash-link" aria-label="概述的直接链接" title="概述的直接链接">​</a></h2><h2 class="anchor anchorWithStickyNavbar_LWe7" id="技术细节">技术细节<a href="#技术细节" class="hash-link" aria-label="技术细节的直接链接" title="技术细节的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="prompts-的初始化">prompts 的初始化<a href="#prompts-的初始化" class="hash-link" aria-label="prompts 的初始化的直接链接" title="prompts 的初始化的直接链接">​</a></h3><p><code>ctx_init </code>参数用于初始化 prompts，官方提供的演示 context 是<code>a photo of a</code>。</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">source_prompts </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">prompt_prefix </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot; &quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> args</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">source_class</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    target_prompts </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">prompt_prefix </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot; &quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> args</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">target_class</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>源域的初始提示词 <code>source_prompts</code> 是 ctx_init 与源域标签的组合。若源域标签为 <code>photo</code>，则源域的初始提示词是 <code>a photo of a photo</code>。目标域的初始提示词同理。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="prompts-的-tokenize-与-embedding">prompts 的 tokenize 与 embedding<a href="#prompts-的-tokenize-与-embedding" class="hash-link" aria-label="prompts 的 tokenize 与 embedding的直接链接" title="prompts 的 tokenize 与 embedding的直接链接">​</a></h3><p>源域以及目标域的初始提示词接下来会进行 tokenize：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">source_tokenized_prompts </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cat</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">clip</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tokenize</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">p</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> p </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> source_prompts</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">to</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">device</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># (1, 77) &#x27;sot a photo of a photo eot&#x27; 在经过tokenize后为tensor [[49406, 320, 1125, 539, 320, 1125, 49407, etc]]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 77是CLIP在tokenize方法中缺省的context_length，超过context_length将被truncate，不足的将用0补齐</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">target_tokenized_prompts </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cat</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">clip</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tokenize</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">p</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> p </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> target_prompts</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">to</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">device</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># (1, 77) &#x27;sot a photo of a disney&#x27; 在经过tokenize后为tensor [[49406, 320, 1125, 539, 320, 4696, 49407, etc]]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 77是CLIP在tokenize方法中缺省的context_length，超过context_length将被truncate，不足的将用0补齐</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>tokenize 是 CLIP 对送入的 prompt 字符串进行标记化处理，在头部和尾部添加 startoftext 以及 endoftext 标记，最终为两个首尾标记和全部单词生成 int 标记。其中 CLIP 模型缺省的 <code>context_length</code> 是77，若 prompt 大于 77 会进行截断（truncate），若小于 77 会进行补零，因此 <code>source_tokenized_prompts</code> 与 <code>target_tokenized_prompts</code> 的形状均为 (1, 77)。</p><p>在提示词标记化之后，将进行嵌入表示 embedding：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">source_embedding </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> clip_model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">source_tokenized_prompts</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">type</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">clip_model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># (1, 77, 512) 其中512是CLIP中的n_dim，token_embedding层的词嵌入的维度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">target_embedding </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> clip_model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">token_embedding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">target_tokenized_prompts</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">type</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">clip_model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dtype</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># (1, 77, 512) 其中512是CLIP中的n_dim，token_embedding层的词嵌入的维度</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="compute_text_features-的实现细节">compute_text_features 的实现细节<a href="#compute_text_features-的实现细节" class="hash-link" aria-label="compute_text_features 的实现细节的直接链接" title="compute_text_features 的实现细节的直接链接">​</a></h3><p>在 Mapper 生成 prompts 后进行 prompts 的特征提取时，需要传入 tokenize 之后的人工初始化 prompt（‘a photo of a photo.’或‘a photo of a disney.’），用于选择 eot 符号对应的维度来进行特征投影（<strong>因为 eot 作为整个句子的结尾，被认为该维度包含更多的信息</strong>。具体做法：由于在 tokenize 之后，eot 符号对应的维度的值最大，因此可使用 argmax 来定位），以保证最后得到的特征形状与图像特征提取的输出形状相同，使得后续可以进行对比学习的损失计算。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="训练-stage-1">训练 stage 1<a href="#训练-stage-1" class="hash-link" aria-label="训练 stage 1的直接链接" title="训练 stage 1的直接链接">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="z空间与w空间">Z空间与W空间<a href="#z空间与w空间" class="hash-link" aria-label="Z空间与W空间的直接链接" title="Z空间与W空间的直接链接">​</a></h4><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Z空间到W空间的变换</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sample_z </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mixing_noise</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">args</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">batch_mapper</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> args</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">mixing</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> device</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># (batch_size, 512)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sample_w </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> net</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generator_frozen</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">style</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sample_z</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># (batch_size, 512)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Z 空间和 W 空间是 StyleGAN 模型中两种不同的隐变量空间，分别用于控制生成图像的随机特征和样式信息。W 空间通过对 Z 空间的映射得到。</p><ol><li><p><strong>Z 空间（Latent Space Z）</strong>：</p><ul><li>Z 空间是随机噪声空间，通常由随机噪声向量组成，表示了图像的随机特征。</li><li>在 StyleGAN 中，Z 空间的维度通常为 512 维。这意味着一个 Z 向量由 512 个数字组成，每个数字表示了图像的一个随机特征的强度或者方向。</li></ul></li><li><p><strong>W 空间（Style Space W）</strong>：</p><ul><li><p>W 空间经过特征解耦的隐空间，与 Z 空间相比更加解耦合。</p></li><li><p>在 StyleGAN 中，W 空间的维度也通常为 512 维，是通过mapping network进行映射得到的，mapping network 由 PixelNorm 层与 EqualLinear 层构成。以下代码节选自<code>sg2_model.py</code>：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&#x27;&#x27;&#x27;mapping network&#x27;&#x27;&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">PixelNorm</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> i </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> </span><span class="token builtin">range</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">n_mlp</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    layers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">append</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        EqualLinear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            style_dim</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> style_dim</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> lr_mul</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">lr_mlp</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> activation</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;fused_lrelu&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">style </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">layers</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li></ul></li><li><p><strong>Z 空间与 W 空间的关系</strong>：</p><ul><li>在 StyleGAN 中，通常会先将一个 Z 向量映射到 W 空间，然后再将 W 向量输入到生成器网络中生成图像。</li><li>Z 空间提供了初始随机噪声，而 W 空间则通过特征解耦提供更多控制图像风格的灵活性。通过对 Z 和 W 之间的映射以及 W 在生成器中的应用，StyleGan 实现了高度可控且具有良好生成效果的图像合成。</li></ul></li></ol><h4 class="anchor anchorWithStickyNavbar_LWe7" id="损失函数">损失函数<a href="#损失函数" class="hash-link" aria-label="损失函数的直接链接" title="损失函数的直接链接">​</a></h4><p>在代码中，stage 1 的损失函数是 <code>global_clip_loss</code>，该损失由三部分组成：</p><ol><li>对比学习损失：Mapper 生成的源域 prompts 的特征<strong>（注意，这里的 prompts 特征是与人工初始化的 prompts 的特征做过 element-wise 相加后的特征）</strong>与源域图像特征的余弦相似度组成的对比学习损失；</li><li>目标域正则化损失：Mapper 生成的目标域 prompts 的特征与目标域文本标签特征的余弦相似度，这里生成的目标域 prompts 特征同样也是与人工初始化的 prompts 做过加法的。注意该损失有权重 <code>lambda_l</code>。</li><li>源域正则化：计算生成的源域prompts与源域标签之间的余弦相似度，由 <code>lambda_src</code> 控制，默认是 0。</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="训练-stage-2">训练 stage 2<a href="#训练-stage-2" class="hash-link" aria-label="训练 stage 2的直接链接" title="训练 stage 2的直接链接">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="确定目标域生成域需要更新的层">确定目标域生成域需要更新的层<a href="#确定目标域生成域需要更新的层" class="hash-link" aria-label="确定目标域生成域需要更新的层的直接链接" title="确定目标域生成域需要更新的层的直接链接">​</a></h4><p>在训练的第二阶段进行前向传播时，需要先对目标域生成器（generator_trainable）的所有层进行 unfreeze，然后对更新哪些层做出选择，承担选择任务的功能函数：model.ZSSGAN.ZSSGAN.determine_opt_layers，最后 freeze 所有层后再 unfreeze 选择的网络层。</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">training </span><span class="token keyword" style="color:#00009f">and</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">auto_layer_iters </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generator_trainable</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">unfreeze_layers</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># unfreeze</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">determine_opt_layers</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># layer to train</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">not</span><span class="token plain"> </span><span class="token builtin">isinstance</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_layers</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token builtin">list</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        train_layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">train_layers</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generator_trainable</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">freeze_layers</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generator_trainable</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">unfreeze_layers</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">train_layers</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># unfreeze</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>具体选择带更新网络层的策略：</p><p>将 W 空间的隐向量送入目标域生成器（SG2Generator）中，并进行反向传播，此时可以通过反向传播后 W 空间隐向量不同维度的更新幅度来衡量不同网络层的影响力，因此选出更新幅度最大的维度就可以确定在 Model Adaption 中需要更新的网络层。</p><p><strong>之所以 W 空间编码在 n_latent 维度上的序号就代表着对应的网络层数的序号，是因为 StyleGAN 生成器的结构决定了这一点：StyleGAN 生成器中，W 空间编码的不同维度会被送入生成器网络的不同层，控制这些层的特征映射 (feature mapping)。具体来说，W 空间编码的每个维度会被重复 n_latent 次，作为该层的风格向量 (style vector)，通过 AdaIN (Adaptive Instance Normalization) 层控制该层的特征映射。因此，W 空间编码的第 i 个维度会影响生成器网络中第 i 层的特征映射。当某个维度的 W 值被更新的程度较大时，就意味着该维度对应的层在生成目标图像时起到了重要作用，需要被优化。</strong></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="损失函数-1">损失函数<a href="#损失函数-1" class="hash-link" aria-label="损失函数的直接链接" title="损失函数的直接链接">​</a></h4><p>stage 2 的损失函数是 CLIP Loss 类中的 <code>clip_directional_loss</code>，该损失函数由两部分组成：</p><ol><li><code>edit_direciton</code>：源域生成器与目标域生成器生成的图片在经过 image encdoer 后做 element-wise 的相减，最后除以自身的 L2 Norm 方便后续与 target_direction 计算余弦相似度。</li><li><code>target_direction</code>：Mapper 产生的源域和目标域 prompts 的 text_features 做element-wise相减后，最后初一自身的 L2 Norm 以便后续与 edit_direction 计算余弦相似度。</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="定量分析指标">定量分析指标<a href="#定量分析指标" class="hash-link" aria-label="定量分析指标的直接链接" title="定量分析指标的直接链接">​</a></h2><p>测试所用 nada 权重 Google Drive 链接：<a href="https://drive.google.com/drive/folders/1Z76nD8pXIL2O5f6xV8VjM4DUCmhbzn0l" target="_blank" rel="noopener noreferrer">StyleGAN-NADA Models</a></p><p>参考文献：<a href="https://blog.csdn.net/qq_35586657/article/details/98478508" target="_blank" rel="noopener noreferrer">GAN 的几种评价指标</a></p><ol><li><p>Inception Score（IS）</p><p><strong>评估图像的质量和多样性</strong></p><p>质量：把生成的图片 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span></span> 输入 Inception V3 中，得到输出 1000 维的向量 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span></span>，向量的每个维度的值对应图片属于某类的概率。对于一个清晰的图片，它属于某一类的概率应该非常大，而属于其它类的概率应该很小。用专业术语说， <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span> 的熵应该很小（熵代表混乱度，均匀分布的混乱度最大，熵最大）。</p><p>多样性： 如果一个模型能生成足够多样的图片，那么它生成的图片在各个类别中的分布应该是平均的，假设生成了 10000 张图片，那么最理想的情况是，1000 类中每类生成了 10 张。转换成术语，就是生成图片在所有类别概率的边缘分布 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span></span> 熵很大（均匀分布）。</p><p>因此，对于 IS 我们需要求的两个量就是 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span> 和 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span></span>。实际中，选取大量生成样本，用经验分布模拟 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span></span>：</p><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><msup><mi mathvariant="bold">x</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{p}(y)=\frac{1}{N}\sum_{i=1}^{N}p(y|\mathbf{x}^{(i)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">p</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1667em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.3262em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><p>Inception Score 的完整公式如下：</p><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>S</mi><mo>=</mo><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi mathvariant="double-struck">E</mi><mi>x</mi></msub><mo stretchy="false">[</mo><mi>K</mi><mi>L</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">IS=\exp\left(\mathbb{E}_x[KL(p(y|x)||p(y))]\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord">∣∣</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">))]</span><span class="mclose delimcenter" style="top:0em">)</span></span></span></span></span></span></p><p>其中 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="double-struck">E</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">\mathbb{E}_x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 表示对所有图像的期望，<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi>L</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">KL(p(y|x)||p(y))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord">∣∣</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">))</span></span></span></span></span> 表示每张图像的 KL 散度，<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>exp</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\exp</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mop">exp</span></span></span></span></span> 表示取指数。</p><p>通常计算 Inception Score 时，会生成 50000 个图片，然后把它分成 10 份，每份 5000 个，分别代入公式计算 10 次 Inception Score，再计算均值和方差，作为最终的衡量指标（均值±方差）。但是 5000 个样本往往不足以得到准确的边缘分布 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span></span>，尤其是像 ImageNet 这种包含 1000 个类的数据集。</p><p>StyleGAN-nada 以及 IPL 在经过 batch_size 为 2，iteration 为 300 的训练后（其中 IPL 的 Mapper 是以 batch_size 为 32，iteration 为 300 进行训练的），二者的 IS 分别为 <code>(2.2960, 0.2042)</code> 以及 <code>(2.6420, 0.1959)</code>。</p></li><li><p>Fréchet Inception Distance（FID）</p><p><strong>评估目标域的风格</strong></p><p>计算 IS 时只考虑了生成样本，没有考虑真实数据，即 <strong>IS 无法反映真实数据和样本之间的距离</strong>，IS 判断数据真实性的依据，源于 Inception V3 的训练集 ImageNet，在 Inception V3 的“世界观”下，凡是不像 ImageNet 的数据，都是不真实的，都不能保证输出一个 sharp 的 predition distribution。因此，要想更好地评价生成网络，就要使用更加有效的方法计算真实分布与生成样本之间的距离。</p><p>FID 距离计算真实样本，生成样本在特征空间之间的距离。首先利用 Inception 网络来提取特征，然后使用高斯模型对特征空间进行建模，再去求解两个特征之间的距离，较低的 FID 意味着较高图片的质量和多样性。</p><p>StyleGAN-nada 以及 IPL 在经过 batch_size 为 2，iteration 为 300 的训练后（其中 IPL 的 Mapper 是以 batch_size 为 32，iteration 为 300 进行训练的），二者的 FID 分别为 <code>84</code> 以及 <code>58</code>。</p></li><li><p>Single Image Fréchet Inception Score（SIFID）</p><p>FID 测量生成的图像的深层特征分布与真实图像的分布之间的偏差。在 ICCV 2019 Best Paper 中提出了 SIFID，只使用一张真实目标域的图像。与 FID 不同，SFID 不使用 Inception Network 中最后一个池化层之后的激活矢量（每个图像一个向量），而是在第二个池层之前的卷积层输出处使用深层特征的内部分布（feature map 中每个位置一个向量）。最终 SIFID 是真实图像和生成的样本中这些特征的统计数据之间的 FID。</p></li><li><p>Structural Consistency Score（SCS）</p><p>评估图像的结构保存能力</p></li><li><p>Identity Similarity（ID）</p><p>评估图像的特征保存能力</p></li></ol><h4 class="anchor anchorWithStickyNavbar_LWe7" id="定量分析结果">定量分析结果<a href="#定量分析结果" class="hash-link" aria-label="定量分析结果的直接链接" title="定量分析结果的直接链接">​</a></h4><p><strong>IS（Inception Score）↑</strong></p><table><thead><tr><th align="center">数据集</th><th align="center">源域→目标域</th><th align="center">NADA</th><th>IPL</th><th>IPL*</th></tr></thead><tbody><tr><td align="center">FFHQ</td><td align="center">Photo→Disney</td><td align="center">2.296</td><td>2.642</td><td><strong>2.701</strong></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Anime Painting</td><td align="center">2.320</td><td>2.464</td><td><strong>2.578</strong></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Wall painting</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Ukiyo-e</td><td align="center">2.489</td><td>2.715</td><td><strong>2.851</strong></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Pixar character</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Tolkien elf</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Werewolf</td><td align="center">2.173</td><td>2.482</td><td><strong>2.517</strong></td></tr><tr><td align="center">AFHQ</td><td align="center">Photo→Cartoon</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">AFHQ</td><td align="center">Photo→Pointillism</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">AFHQ</td><td align="center">Photo→Cubism</td><td align="center"></td><td></td><td></td></tr></tbody></table><p><strong>SFID（Single Fréchet Inception Distance）↓</strong></p><table><thead><tr><th align="center">数据集</th><th align="center">源域→目标域</th><th align="center">NADA</th><th>IPL</th><th>IPL*</th></tr></thead><tbody><tr><td align="center">FFHQ</td><td align="center">Photo→Disney</td><td align="center">84</td><td>58</td><td><strong>54</strong></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Anime Painting</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Wall painting</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Ukiyo-e</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Pixar character</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Tolkien elf</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">FFHQ</td><td align="center">Photo→Werewolf</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">AFHQ</td><td align="center">Photo→Cartoon</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">AFHQ</td><td align="center">Photo→Pointillism</td><td align="center"></td><td></td><td></td></tr><tr><td align="center">AFHQ</td><td align="center">Photo→Cubism</td><td align="center"></td><td></td><td></td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="新增功能">新增功能<a href="#新增功能" class="hash-link" aria-label="新增功能的直接链接" title="新增功能的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="支持自定义图像的风格迁移">支持自定义图像的风格迁移<a href="#支持自定义图像的风格迁移" class="hash-link" aria-label="支持自定义图像的风格迁移的直接链接" title="支持自定义图像的风格迁移的直接链接">​</a></h3><p>新增了对自定义图像进行风格迁移的功能。</p><p> <a href="https://yuval-alaluf.github.io/hyperstyle/" target="_blank" rel="noopener noreferrer">HyperStyle </a>中的 e4e encoder 将自定义的真实图像编码至 StyleGAN2 中的 W 空间生成 latent codes，再将其分别输入至源域生成器以及目标域生成器以代替原始的从正态分布中 sample 出的随机向量生成的 <code>w_codes</code>，从而得到相应的图片。其中 e4e encoder 来源于 HyperStyle 提供的预训练 checkpoint。</p><p>使用方法：运行 <code>inference.py</code>，设置对应的参数，如生成器以及 e4e encoder 的路径、图像路径等，最后运行即可。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="修改日志">修改日志<a href="#修改日志" class="hash-link" aria-label="修改日志的直接链接" title="修改日志的直接链接">​</a></h4><ol><li>第一次尝试只加载了 <code>w_encoder</code> 类及其对应 checkpoint 参数，导致并未将真实图片编码到 StyleGAN 的 W 空间中，没有 inversion 出合理的结果。</li><li>第二次尝试使用了 <code>restyle_e4e_encoder</code>，但是没有使用 dlib 进行 alignment，也没有使用 restyle 模型在反演时使用的多次进行前向传播来修正 latent code 的策略。此次尝试虽然反演出了合理的人像，但是人像的特征保存能力非常弱。</li><li>第三次尝试解决了上一次发现的问题，加入 dlib 提供的 landmark 检测以实现 alignment，并且使用 <code>run_loop</code> 函数在 restyle_e4e_encoder 中进行多次前向传播以修正得到的 W 空间的 latent code，效果较好。</li><li>对比 pSp 和 e4e encoder，pSp 对人脸图像的还原能力较强，但是会导致目标域图像具有随机的彩色光晕。</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="web-ui">Web UI<a href="#web-ui" class="hash-link" aria-label="Web UI的直接链接" title="Web UI的直接链接">​</a></h3><p>参考 MIT 开源项目 <a href="https://github.com/songquanpeng/pytorch-deployment" target="_blank" rel="noopener noreferrer">pytorch-deployment</a> 进行生成模型的 Web UI 部署。参考项目使用的是 <a href="https://github.com/clovaai/stargan-v2" target="_blank" rel="noopener noreferrer">StarGANv2</a> 模型，对其进行优化使得其可以部署 StyleGAN 模型。</p><p>分别对人像和宠物图像生成了两个单独的卡片和 HTML 网页，网页可以完成两种功能：</p><ol><li>使用参考图像进行零样本跨域适应，同时可以在网页下拉框中选择预期的目标域风格（由于没有合适的 restyle encoder，宠物图像不支持选择参考图像）</li><li>直接使用随机数生成源域图像并进行零样本跨域适应</li></ol><p>UI 独立代码可以参考本人仓库 <a href="https://github.com/bonjour-npy/stylegan-ui" target="_blank" rel="noopener noreferrer">stylegan-ui</a>，但功能有限，完整的 UI 代码已经合并到主程序中，请参考 <code>./web_ui</code> 中的具体代码。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="部分效果展示图">部分效果展示图<a href="#部分效果展示图" class="hash-link" aria-label="部分效果展示图的直接链接" title="部分效果展示图的直接链接">​</a></h4><p>主页：</p><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240426191139926.png" alt="image-20240426191139926" class="img_ev3q"></p><p>人物画像的零样本域适应（初始状态）：</p><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240426191201479.png" alt="image-20240426191201479" class="img_ev3q"></p><p>人物画像的零样本域适应（使用参考图像生成状态）：</p><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240425222843497.png" alt="image-20240425222843497" class="img_ev3q"></p><p>宠物画像的零样本域适应（初始状态）：</p><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240426191227686.png" alt="image-20240426191227686" class="img_ev3q"></p><p>宠物画像的零样本域适应（使用随机数生成状态）：</p><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240425223227958.png" alt="image-20240425223227958" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="问题提出与改进">问题提出与改进<a href="#问题提出与改进" class="hash-link" aria-label="问题提出与改进的直接链接" title="问题提出与改进的直接链接">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="改进mapper-结构的设计">改进：Mapper 结构的设计<a href="#改进mapper-结构的设计" class="hash-link" aria-label="改进：Mapper 结构的设计的直接链接" title="改进：Mapper 结构的设计的直接链接">​</a></h3><p>Mapper 的作用是从 W 空间的隐式代码中学习出符合源域图片特征以及符合目标域文字特征的 prompts。</p><p>改进后的 Mapper 结构：</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">TransformerMapperV2</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    改良版transformer mapper，增加多头注意力，减小transformer encoder的层数，防止学习到的源域图像细节过拟合</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    同时去掉开头的PixelNorm，防止与transformer中的layer normalization冲突</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    并在transformer encoder之后加入Pixel Norm以及全连接层</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> opts</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_dim</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">TransformerMapperV2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">opts </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> opts</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">n_dim </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> n_dim</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        layers </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># transformer中有layer normalization，不需要进行PixelNorm</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 自定义Transformer编码器层配置</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        transformer_layer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TransformerEncoderLayer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">d_model</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> nhead</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dim_feedforward</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1024</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dropout</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 构建Transformer编码器</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformer_encoder </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TransformerEncoder</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">transformer_layer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> num_layers</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        layers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">append</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformer_encoder</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 再过一次PixelNorm以及全连接层，将每个点归一化（除以模长），避免输入noise的极端权重，改善稳定性</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        layers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">append</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">PixelNorm</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">linear </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> EqualLinear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> lr_mul</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.01</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> activation</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;fused_lrelu&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        layers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">append</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">linear</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># 最后一个全连接层，输出维度保持不变</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">final_linear </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> EqualLinear</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> n_dim </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> opts</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">n_ctx</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> lr_mul</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.01</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> activation</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;fused_lrelu&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        layers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">append</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">final_linear</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">mapping </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">*</span><span class="token plain">layers</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">to</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">device</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="问题训练阶段人工-prompts-的作用是什么">问题：训练阶段人工 prompts 的作用是什么？<a href="#问题训练阶段人工-prompts-的作用是什么" class="hash-link" aria-label="问题：训练阶段人工 prompts 的作用是什么？的直接链接" title="问题：训练阶段人工 prompts 的作用是什么？的直接链接">​</a></h3><p>在 IPL 的官方代码实现中，人工设计的 prompts 有两处，一是 <code>ctx_init</code>，由命令行参数赋值，即 &quot;a photo of a&quot;，另一处是 utils/text_templates.py 中的 templates，下面分别分析这两处的具体作用。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="ctx_init-的作用与域标签拼接后的-ctx_init">ctx_init 的作用（与域标签拼接后的 ctx_init）<a href="#ctx_init-的作用与域标签拼接后的-ctx_init" class="hash-link" aria-label="ctx_init 的作用（与域标签拼接后的 ctx_init）的直接链接" title="ctx_init 的作用（与域标签拼接后的 ctx_init）的直接链接">​</a></h4><ol><li><p><code>ctx_init</code> 在 <code>compute_text_features</code> 函数中用于定位 <code>eot</code> 层符号所表示的维度来进行投影，使得文字特征与图像特征维度相同，并不参与 <code>text_features</code> 的实际计算。但是在该函数中，Mapper 输出的 image-specific prompts 已经与域标签的嵌入表示进行了 concat。</p></li><li><p>在 stage 1 训练 Mapper 损失函数中，Mapper 学习到的 image-specfic prompts 在与源域标签进行 concat 并得到文字编码后，会与 ctx_init 的文字编码进行 element-wise 的相加，最后再与源域生成器输出的图片的图像编码进行对比损失计算；</p><p>同理，在 stage 2 训练目标域生成器时，Mapper 输出的 image-specific prompts 在分别与源域、目标域标签 concat 后送入文字编码器得到文字特征，再与 ctx_init 的文字特征进行 element-wise 相加，最后二者相减得到 text_direction。</p></li></ol><h4 class="anchor anchorWithStickyNavbar_LWe7" id="templates-的作用">templates 的作用<a href="#templates-的作用" class="hash-link" aria-label="templates 的作用的直接链接" title="templates 的作用的直接链接">​</a></h4><p>templates 是提前准备好的一系列字符串，其中字符串的格式全部类似于 <code>a photo of a {}.</code></p><p>原始 hhfq 数据集的模板共有 79 个字符串。</p><p>与 <code>ctx_init</code> 起作用的函数不同，templates 在第一阶段的训练的 domain regularization loss 中使用到的 <code>get_text_features</code> 函数起作用，用于与目标域标签进行格式化连接后成为 image-specific prompts 向目标域靠近的方向。即 domain loss 使学习到的 prompts 向以目标域标签为中心的字符串对齐。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="思考">思考<a href="#思考" class="hash-link" aria-label="思考的直接链接" title="思考的直接链接">​</a></h4><p>IPL 方法对 Mapper 学习到的 prompts 除了（1）使用对比学习使 prompts 学习到源域图片的特征以及（2）使用域正则化使得 prompts 向目标域标签对齐之外，并没有使用其他与人工设计的 prompts 有关的正则化方式来约束 prompts 的学习，因此人工设计的 prompts 可能并没有起到太大的约束作用。</p><p>如果对比学习损失是为了让 Mapper 自监督学习到图片的特征外，那么是否可以对域正则化损失进行改进，约束学习到的 prompts 向人工设计的初始化 prompts 对齐，以实现类似于 Stable Diffusion 类似的 prompts 控制图像生成的效果。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="改进使学习到的-prompts-向用户自主设计的-prompts-模板对齐">改进：使学习到的 prompts 向用户自主设计的 prompts 模板对齐<a href="#改进使学习到的-prompts-向用户自主设计的-prompts-模板对齐" class="hash-link" aria-label="改进：使学习到的 prompts 向用户自主设计的 prompts 模板对齐的直接链接" title="改进：使学习到的 prompts 向用户自主设计的 prompts 模板对齐的直接链接">​</a></h3><p>对第一阶段的损失函数做出修改，更新domain loss，将原始 domain loss 中使用的以目标域标签为中心的模板更换成自定义模板，使目标域的image-specific prompts与自定义模板对齐。</p><p>经过多次实验和分析，刻意让 Mapper 输出的image-specific prompts 去逼近用户设置的 prompts，会产生一些隐式细节的丢失。因为 Mapper 本身存在的目的就是学习出人工无法准确描述的细节（包括源域图像的自身细节以及目标域风格的细节），如果对 Mapper 的损失函数中加上太多人为设计的限制，很显然会造成细节的丢失并且出现同质的现象。</p><p>因此，为了达到既使用精心设计的 prompts 来优化域适应，同时又不影响 Mapper 自主学习双域特征，在原有两个损失函数的基础上，新增一个权重较小的损失函数，用于将 Mapper 学习到的目标域 prompts 向自定义模板对齐。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="用于生成-prompts-的-gptclaude-prompts">用于生成 prompts 的 GPT、Claude prompts<a href="#用于生成-prompts-的-gptclaude-prompts" class="hash-link" aria-label="用于生成 prompts 的 GPT、Claude prompts的直接链接" title="用于生成 prompts 的 GPT、Claude prompts的直接链接">​</a></h4><p>中文提示词：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">针对将普通人像转换成迪士尼风格人物画像的任务，给出60个描述迪士尼人像特有特征的文字prompt。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">将上述生成的60个prompts放在同一个Python列表中，即每一个prompt作为该列表的字符串元素，输出整个Python列表。</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>英文提示词：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">For the task of converting a {source class} photo into a {target_class} photo,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">provide some text prompts describing the distinctive features of Disney character portraits.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Put the generated 60 prompts into the same Python list, with each prompt as a string element of the list,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">and output the entire Python list.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="复制代码到剪贴板" title="复制" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="对-global_clip_loss-的改进">对 global_clip_loss 的改进<a href="#对-global_clip_loss-的改进" class="hash-link" aria-label="对 global_clip_loss 的改进的直接链接" title="对 global_clip_loss 的改进的直接链接">​</a></h4><p>IPL 训练第一阶段的损失函数除了源域 prompts 与源域图像之间的对比学习损失函数外，还有将目标域 prompts 与目标域标签计算余弦相似度的 domain regularization。</p><p>对 domain regularization 进行改进，引入开发者自定义的 prompts，约束 Mapper 学习到的目标域 prompts 向开发者自定义的 prompts 对齐，以此来进行 prompt tuning，发挥 prompt learning 的更大优势，并增强自定义性。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="对-clip_directional_loss-的改进">对 clip_directional_loss 的改进<a href="#对-clip_directional_loss-的改进" class="hash-link" aria-label="对 clip_directional_loss 的改进的直接链接" title="对 clip_directional_loss 的改进的直接链接">​</a></h4><p>IPL 训练第二阶段的损失函数，使用 criteria.clip_loss.CLIPLoss.clip_directional_loss。</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Deep-Learning/大模型基础/Sampling-for-Generation"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">生成模型中的采样技巧</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Deep-Learning/论文笔记/Attention-Is-All-You-Need"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">NeurIPS 2017: Attention Is All You Need</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#依赖" class="table-of-contents__link toc-highlight">依赖</a><ul><li><a href="#创建-anaconda-虚拟环境" class="table-of-contents__link toc-highlight">创建 Anaconda 虚拟环境</a></li><li><a href="#安装依赖" class="table-of-contents__link toc-highlight">安装依赖</a></li><li><a href="#下载预训练生成器" class="table-of-contents__link toc-highlight">下载预训练生成器</a></li></ul></li><li><a href="#概述" class="table-of-contents__link toc-highlight">概述</a></li><li><a href="#技术细节" class="table-of-contents__link toc-highlight">技术细节</a><ul><li><a href="#prompts-的初始化" class="table-of-contents__link toc-highlight">prompts 的初始化</a></li><li><a href="#prompts-的-tokenize-与-embedding" class="table-of-contents__link toc-highlight">prompts 的 tokenize 与 embedding</a></li><li><a href="#compute_text_features-的实现细节" class="table-of-contents__link toc-highlight">compute_text_features 的实现细节</a></li><li><a href="#训练-stage-1" class="table-of-contents__link toc-highlight">训练 stage 1</a><ul><li><a href="#z空间与w空间" class="table-of-contents__link toc-highlight">Z空间与W空间</a></li><li><a href="#损失函数" class="table-of-contents__link toc-highlight">损失函数</a></li></ul></li><li><a href="#训练-stage-2" class="table-of-contents__link toc-highlight">训练 stage 2</a><ul><li><a href="#确定目标域生成域需要更新的层" class="table-of-contents__link toc-highlight">确定目标域生成域需要更新的层</a></li><li><a href="#损失函数-1" class="table-of-contents__link toc-highlight">损失函数</a></li></ul></li></ul></li><li><a href="#定量分析指标" class="table-of-contents__link toc-highlight">定量分析指标</a><ul><li><a href="#定量分析结果" class="table-of-contents__link toc-highlight">定量分析结果</a></li></ul></li><li><a href="#新增功能" class="table-of-contents__link toc-highlight">新增功能</a><ul><li><a href="#支持自定义图像的风格迁移" class="table-of-contents__link toc-highlight">支持自定义图像的风格迁移</a><ul><li><a href="#修改日志" class="table-of-contents__link toc-highlight">修改日志</a></li></ul></li><li><a href="#web-ui" class="table-of-contents__link toc-highlight">Web UI</a><ul><li><a href="#部分效果展示图" class="table-of-contents__link toc-highlight">部分效果展示图</a></li></ul></li></ul></li><li><a href="#问题提出与改进" class="table-of-contents__link toc-highlight">问题提出与改进</a><ul><li><a href="#改进mapper-结构的设计" class="table-of-contents__link toc-highlight">改进：Mapper 结构的设计</a></li><li><a href="#问题训练阶段人工-prompts-的作用是什么" class="table-of-contents__link toc-highlight">问题：训练阶段人工 prompts 的作用是什么？</a><ul><li><a href="#ctx_init-的作用与域标签拼接后的-ctx_init" class="table-of-contents__link toc-highlight">ctx_init 的作用（与域标签拼接后的 ctx_init）</a></li><li><a href="#templates-的作用" class="table-of-contents__link toc-highlight">templates 的作用</a></li><li><a href="#思考" class="table-of-contents__link toc-highlight">思考</a></li></ul></li><li><a href="#改进使学习到的-prompts-向用户自主设计的-prompts-模板对齐" class="table-of-contents__link toc-highlight">改进：使学习到的 prompts 向用户自主设计的 prompts 模板对齐</a><ul><li><a href="#用于生成-prompts-的-gptclaude-prompts" class="table-of-contents__link toc-highlight">用于生成 prompts 的 GPT、Claude prompts</a></li><li><a href="#对-global_clip_loss-的改进" class="table-of-contents__link toc-highlight">对 global_clip_loss 的改进</a></li><li><a href="#对-clip_directional_loss-的改进" class="table-of-contents__link toc-highlight">对 clip_directional_loss 的改进</a></li></ul></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">👋 联系我</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/WeChat_QR_Code.jpg" target="_blank" rel="noopener noreferrer" class="footer__link-item">WeChat<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.douyin.com/user/self?modal_id=7157246567970360614" target="_blank" rel="noopener noreferrer" class="footer__link-item">TikTok<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">✈️ 外部链接</div><ul class="footer__items clean-list"><li class="footer__item"><a href="http://www.mod.gov.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">共和国国防部<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.xuexi.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">学习强国<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://peacekeeping.un.org/zh" target="_blank" rel="noopener noreferrer" class="footer__link-item">联合国维持和平<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🎅 彩蛋</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.rockstargames.com/gta-v" target="_blank" rel="noopener noreferrer" class="footer__link-item">欢迎来到洛圣都<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.starwars.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">星球大战<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apple.com.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Apple(中国大陆)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🦄 教育官网</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.uestc.edu.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.guet.edu.cn" target="_blank" rel="noopener noreferrer" class="footer__link-item">桂林电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://cfm.uestc.edu.cn/index" target="_blank" rel="noopener noreferrer" class="footer__link-item">未来媒体研究中心<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><br>本网站所展示的标识、链接均属于个人创作和喜好表达，不代表任何国家、政府、企业或组织的官方立场或行为。<br>
                    尽管本网站努力确保信息的准确性和时效性，但所有信息仅供参考，并不构成任何形式的法律、财务或商业建议。<br>
                    <br>Copyright © 2024 bonjour-npy. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.ca8e12bd.js"></script>
<script src="/assets/js/main.d56e5793.js"></script>
</body>
</html>