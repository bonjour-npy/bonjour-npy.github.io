# 图像生成：自回归模型

自回归模型（Autoregressive Models）在图像生成领域扮演着重要角色，它们基于一个核心假设：当前像素值依赖于之前的像素值。这种依赖关系可以通过条件概率来表达，其中每一个像素的生成都是基于之前已经生成的像素的条件分布。在传统的视觉自回归图像生成任务中，这通常意味着从左到右和从上到下的顺序生成每个像素。

## 自回归模型的数学定义

自回归（Autoregressive，简称AR）模型是一种统计模型，用于描述时间序列中的每个值作为其之前值的函数。在机器学习中，自回归模型被广泛应用于序列数据的生成任务，如文本、语音和图像生成。自回归模型通过逐步预测下一个值，依次生成整个序列。

假设有一个序列 $x=\left(x_1, x_2, \ldots, x_T\right)$ ，自回归模型的目标是学习条件概率分布 $p\left(x_t \mid x_{<t}\right)$ ， 即在给定序列前面部分 $x_{<t}=\left(x_1, x_2, \ldots, x_{t-1}\right)$ 的情况下，预测当前值 $x_t$ 。

对于一个给定的序列 $x$ ，自回归模型的联合概率分布可以分解为以下形式:
$$
p(x)=\prod_{t=1}^T p\left(x_t \mid x_{<t}\right)
$$

在图像生成任务中，图像被看作是一个二维序列。在传统的自回归图像生成模型（VQVAE、VQGAN 等）将图像的像素视作一个一维序列，通过条件概率分布 $p\left(x_{i, j} \mid x_{<i, j}\right)$ 来生成每个像素值 $x_{i, j}$ 。

## Autoregressive 模型时间线

### PixelRNN（2016）

PixelRNN 是早期的自回归模型之一，它使用循环神经网络（RNN）来建模条件概率分布。由于 RNN 能够捕捉长序列依赖性，PixelRNN 能够生成高质量的图像，但是计算效率较低，因为每次生成一个像素都需要遍历整个序列。

### PixelCNN（2016）

为了克服 PixelRNN 的计算瓶颈，PixelCNN 使用卷积神经网络（CNN）并引入了遮罩技术，确保每个像素仅依赖于其上方和左侧的像素。

### VQ-VAE（2017）

在[科学空间：VQ-VAE 的简明介绍](https://www.spaces.ac.cn/archives/6760)中，提到了 VQ-VAE 与之前的 PixelCNN 和 PixelRNN 的关系。

受 PixelCNN 和 PixelRNN 专注于像素级的生成的启发，VQ-VAE（Vector Quantized Variational Autoencoder）提出了另一种方法，通过离散的潜在空间来建模数据。VQ-VAE 的主要贡献在于引入了向量量化层，将连续的潜在变量映射到一组离散的嵌入向量上，从而能够更高效地学习复杂的数据分布。

**主要思想**：VQ-VAE（Vector Quantized Variational AutoEncoder）通过将连续的图像表示量化为离散的代码来进行图像生成。它引入了一个离散的代码本，将连续的潜在向量映射到离散的代码上，进行编码和解码。

**主要贡献**：

- 采用向量量化方法，使得生成模型能够高效地处理离散代码。
- 在生成模型中，离散化的潜在空间简化了模型的训练和推理过程。

**与之前模型的关系**：

- VQ-VAE 在 VAEs（Variational AutoEncoders）的基础上，引入了离散的潜在空间，使得生成效果更好，训练更稳定。

### VQVAE-2（2019）

VQVAE-2 是 VQ-VAE 的一个扩展版本，它引入了层次化的结构，使用多个层次的量化向量来建模不同尺度的特征，从而提高了模型的灵活性和生成图像的质量。

**主要思想**：VQ-VAE-2 引入了多层级的离散潜在变量，通过多层级的自回归模型进行生成。它使用了层次化的编码器和解码器结构，更好地捕捉图像中的复杂结构。

**主要贡献**：

- 引入了层次化的离散潜在空间，提高了生成图像的质量和分辨率。
- 在多个层级上进行自回归生成，提高了模型对图像全局和局部信息的捕捉能力。

**改进点**：

- 相较于 VQ-VAE，VQ-VAE-2 通过层次化的设计，显著提升了生成图像的细节和清晰度。

### VQGAN（2021）

VQGAN 结合了 VQ-VAE 的思想和生成对抗网络（GANs）的优点。它使用编码器和解码器之间的量化瓶颈，并利用 GAN 框架来优化图像质量。VQGAN 在高分辨率图像生成方面表现出了强大的能力。

**主要思想**：VQGAN（Vector Quantized Generative Adversarial Networks）结合了 VQ-VAE 的离散潜在表示和 GAN（Generative Adversarial Networks）的对抗训练，提升了生成图像的质量。

**主要贡献**：

- 利用对抗训练，生成的图像更加逼真和细腻。
- 通过结合 VQ-VAE 和 GAN 的优势，解决了各自方法的一些固有缺陷。

**改进点**：

- 相较于 VQ-VAE-2，VQGAN 通过对抗训练机制，进一步提升了生成图像的视觉质量。

### RQTransformer（2021）

RQTransformer 是一种改进的自回归模型，它利用了自注意力机制，能够有效地处理序列数据。相比于传统的自回归模型，RQTransformer 在大规模数据集上展现了更好的性能，尤其是在自然语言处理和图像生成任务中。

**主要思想**：RQ-Transformer（Residual Quantization Transformer）结合了残差量化和 Transformer 架构，通过对潜在空间进行分块量化来提高生成效率和质量。

**主要贡献**：

- 引入残差量化方法，提高了潜在空间的表示能力。
- 结合 Transformer 架构，增强了对复杂图像结构的建模能力。

**改进点**：

- 相较于 VQ-VAE 和 VQGAN，RQ-Transformer 在潜在空间表示上更为灵活，提高了生成图像的分辨率和质量。

### DALL-E（2021）

**主要思想**：DALL-E 是 OpenAI 提出的一个基于 Transformer 的图像生成模型，能够根据文本描述生成图像。它使用了大规模的文本-图像对数据进行训练，并采用了自回归生成策略。其创新之处在于如何将文本和图像模态融合在一起。

**主要贡献**：

- 展示了基于文本描述生成图像的强大能力。
- 引入了大规模数据和 Transformer 架构，使得生成效果更加多样化和逼真。

**改进点**：

- 相较于之前的图像生成模型，DALL-E 在生成多样性和一致性上有了显著提升，特别是在文本到图像的生成任务中表现出色。

### Parti（2022）

Parti 是谷歌研究团队提出的一种模型，专注于分层次的图像生成。它首先生成图像的组成部分（如物体或场景元素），然后将这些部分组合成完整的图像。Parti 在保持图像细节的同时，还能够控制图像的语义内容。

**主要思想**：Parti 是一个基于 Transformer 的图像生成模型，能够通过部分图像生成剩余部分。它采用了多阶段生成策略，通过逐步细化生成图像，保证生成效果的一致性和逼真性。

**主要贡献**：

- 引入了多阶段的生成策略，提高了生成图像的一致性。
- 在部分图像生成任务中表现出色，能够根据现有图像生成补全部分。

**改进点**：

- 相较于 DALL-E 和其他自回归模型，Parti 在生成图像的一致性和细节捕捉上有了显著改进。