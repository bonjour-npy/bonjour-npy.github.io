<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Tui-Mian/简历/简历面试准备" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.6.3">
<title data-rh="true">简历面试准备 | 培洋的主页 🏠</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://bonjour-npy.github.io/./static/img/intro.png"><meta data-rh="true" name="twitter:image" content="https://bonjour-npy.github.io/./static/img/intro.png"><meta data-rh="true" property="og:url" content="https://bonjour-npy.github.io/docs/Tui-Mian/简历/简历面试准备"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="简历面试准备 | 培洋的主页 🏠"><meta data-rh="true" name="description" content="一、U-2-Net"><meta data-rh="true" property="og:description" content="一、U-2-Net"><link data-rh="true" rel="icon" href="/img/rockstar-games.svg"><link data-rh="true" rel="canonical" href="https://bonjour-npy.github.io/docs/Tui-Mian/简历/简历面试准备"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/en/docs/Tui-Mian/简历/简历面试准备" hreflang="en"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Tui-Mian/简历/简历面试准备" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Tui-Mian/简历/简历面试准备" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.f6a258e4.css">
<script src="/assets/js/runtime~main.e3115889.js" defer="defer"></script>
<script src="/assets/js/main.f04c4d37.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const a=new URLSearchParams(window.location.search).entries();for(var[t,e]of a)if(t.startsWith("docusaurus-data-")){var n=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(n,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><div class="announcementBar_mb4j" role="banner"><div class="content_knG7 announcementBarContent_xLdY">✨ 求实求真，大气大为 ✨</div></div><nav aria-label="主导航" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/navbar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/navbar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">培洋的主页 🌐</b></a><a class="navbar__item navbar__link" href="/docs/Deep-Learning/intro">🤖 深度学习</a><a class="navbar__item navbar__link" href="/docs/GPU-Server/intro">🌍 服务器相关</a><a class="navbar__item navbar__link" href="/docs/Tui-Mian/intro">🤡 推免</a><a class="navbar__item navbar__link" href="/docs/Algorithms/intro">🎰 算法</a><a class="navbar__item navbar__link" href="/docs/Curriculum/intro">📖 课程学习</a><a class="navbar__item navbar__link" href="/docs/Others/intro">☃️ 其他</a><a class="navbar__item navbar__link" href="/docs/Acknowledgement/intro">🍺 饮水思源</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Tui-Mian/intro">Welcome</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Tui-Mian/Summary">经验贴：2023年双非计算机保研经历</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Tui-Mian/数学/夏令营面试数学部分复习">数学</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Tui-Mian/机试/大数除法">机试</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/Tui-Mian/简历/简历面试准备">简历</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Tui-Mian/简历/简历面试准备">简历面试准备</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Tui-Mian/计算机基础综合/数据结构">计算机基础综合</a></div></li></ul></nav><button type="button" title="收起侧边栏" aria-label="收起侧边栏" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">简历</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">简历面试准备</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>简历面试准备</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="一u-2-net">一、U-2-Net<a href="#一u-2-net" class="hash-link" aria-label="一、U-2-Net的直接链接" title="一、U-2-Net的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="一sod任务">（一）SOD任务<a href="#一sod任务" class="hash-link" aria-label="（一）SOD任务的直接链接" title="（一）SOD任务的直接链接">​</a></h3>
<p>显著性目标检测Salient Object Detection，相当于语义分割中的二分类任务，只有前景和背景</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="二网络结构">（二）网络结构<a href="#二网络结构" class="hash-link" aria-label="（二）网络结构的直接链接" title="（二）网络结构的直接链接">​</a></h3>
<p>下图为U-2-Net的整体结构</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesimage-20230618103036971.png" alt="image-20230618103036971" class="img_ev3q"></p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>residual [rɪˈzɪdjuəl]</p></div></div>
<p>在encoder阶段，每个block之后使用maxpooling下采样两倍
在decoder阶段，每个block之后使用双线性插值上采样两倍</p>
<p>下图为Residual U-block的结构</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesimage-20230618103937905.png" alt="image-20230618103937905" class="img_ev3q"></p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>卷积是如何改变输出的通道数的？
<img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesv2-ec760bd24d7c00de5eef31cde2a4b33c_720w.webp" alt="img" class="img_ev3q"></p><p>卷积核的通道数等于输入的通道数，卷积核的个数等于输出的通道数</p><p><a href="https://www.zhihu.com/question/474159106/answer/2014764112" target="_blank" rel="noopener noreferrer">图片来源知乎</a></p></div></div>
<p>在特征融合阶段，每一层的encoder-decoder输出，使用3x3卷积以及双线性插值上采样到原始分辨率得到该层的特征图，且卷积核的个数为1，输出的feature map通道数也为1。将每一层的feature map进行concat拼接，得到6通道的融合feature map，最后使用1x1卷积以及sigmoid激活函数得到最终的融合特征图输出</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="三损失函数">（三）损失函数<a href="#三损失函数" class="hash-link" aria-label="（三）损失函数的直接链接" title="（三）损失函数的直接链接">​</a></h3>
<p>损失函数是7个损失项的加权求和
共有6层encoder-decoder结构，将每一层对应的feature map与ground truth做BCE Loss得到6个损失项
第7个损失项是最终融合得到的feature map与ground truth的BCE Loss
在论文中，每个损失项的权重都为1</p>
<p>canny边缘检测：</p>
<ol>
<li>使用高斯滤波进行平滑</li>
<li>计算像素梯度</li>
<li>非极大值抑制</li>
<li>双阈值检测强边缘、弱边缘</li>
<li>边缘连接</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="四深度可分离卷积">（四）深度可分离卷积<a href="#四深度可分离卷积" class="hash-link" aria-label="（四）深度可分离卷积的直接链接" title="（四）深度可分离卷积的直接链接">​</a></h3>
<p>深度可分离卷积的优点是可以在大致保持卷积效果的情况下减少参数量</p>
<p>在实现原理上可分为两个步骤：深度卷积（depth wise）以及逐点（point wise）卷积</p>
<p>深度卷积是一种在每个输入通道上分别进行卷积操作的卷积方法，每个输入通道只与对应的卷积核进行卷积。</p>
<p>逐点卷积通过使用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1 \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>卷积对深度卷积的结果再次卷积</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="二yolo">二、YOLO<a href="#二yolo" class="hash-link" aria-label="二、YOLO的直接链接" title="二、YOLO的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="一map">（一）mAP<a href="#一map" class="hash-link" aria-label="（一）mAP的直接链接" title="（一）mAP的直接链接">​</a></h3>
<p>PR曲线所围成的面积即使该类的AP值</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesimage-20230618120734230.png" alt="image-20230618120734230" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="二yolov1">（二）YOLOv1<a href="#二yolov1" class="hash-link" aria-label="（二）YOLOv1的直接链接" title="（二）YOLOv1的直接链接">​</a></h3>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>参考资料：<a href="https://www.bilibili.com/video/BV15w411Z7LG?p=4&amp;vd_source=24d8fcf68bc0e2b0003defe0995cf533" target="_blank" rel="noopener noreferrer">【精读AI论文】YOLO V1目标检测，看我就够了</a></p></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1预测阶段">1.预测阶段<a href="#1预测阶段" class="hash-link" aria-label="1.预测阶段的直接链接" title="1.预测阶段的直接链接">​</a></h4>
<p>下图为YOLOv1的算法框架</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesimage-20230618122157583.png" alt="image-20230618122157583" class="img_ev3q"></p>
<p>下图为YOLOv1的网络结构</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesimage-20230618122438429.png" alt="image-20230618122438429" class="img_ev3q"></p>
<p>输入[448, 448, 3]图像，输出[7, 7, 30]的tensor（包含所有预测框的坐标、置信度和类别结果），通过解析输出的tensor得到预测结果</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesimage-20230618122634451.png" alt="image-20230618122634451" class="img_ev3q"></p>
<p>首先将输入图片划分为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>×</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">S \times S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span></span>个grid cell。在YOLOv1中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>=</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">S=7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">7</span></span></span></span></p>
<p>每个grid cell预测出<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>个bounding box预测框（bbox），每个bbox的中心点都落在该grid cell中。在YOLOv1中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">B=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span></p>
<p>每个bbox包含(x, y, h, w, c)五种信息，其中x, y为bbox左上角坐标，h, w为bbox的宽高，c为该bbox是否存在object的概率</p>
<p>同时每个grid cell预测出一组与数据集有关的条件类别概率。在YOLOv1论文使用的数据集Pascal VOC中，类别种类为20类，因此在预测阶段输出的[7, 7, 30]的tensor含义如下图所示</p>
<p>每个grid cell选出条件类别概率最大的类别，因此每个grid cell只能检测一个物体</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>这也是YOLOv1小目标和密集目标识别能力差的原因</p></div></div>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/windows_typora/image-20230708094841128.png" alt="image-20230708094841128" class="img_ev3q"></p>
<p>每个bbox的置信度与其父grid cell的类别概率相乘得到全概率，如下图所示</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/windows_typora/image-20230708100637488.png" alt="image-20230708100637488" class="img_ev3q"></p>
<p>进行NMS后处理：</p>
<ol>
<li>对某一特定类别，首先根据全概率置信度排序</li>
<li>将此时最大置信度的bbox与其他所有置信度更小的bbox做IoU判断，若IoU大于设置的阈值，则抹除置信度小的bbox</li>
<li>将剩余的次大的置信度重复步骤2，抹除所有置信度更小的其IoU超过阈值的bbox</li>
</ol>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>非极大值抑制只在预测阶段进行</p><p>在训练阶段，所有bbox都会在Loss Function中起到更新的作用，因此不进行NMS</p></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-训练过程的损失函数">2. 训练过程的损失函数<a href="#2-训练过程的损失函数" class="hash-link" aria-label="2. 训练过程的损失函数的直接链接" title="2. 训练过程的损失函数的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesimage-20230618135151404.png" alt="image-20230618135151404" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="二yolov2">（二）YOLOv2<a href="#二yolov2" class="hash-link" aria-label="（二）YOLOv2的直接链接" title="（二）YOLOv2的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-bn层">1. BN层<a href="#1-bn层" class="hash-link" aria-label="1. BN层的直接链接" title="1. BN层的直接链接">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/windows_typora/image-20230711101245141.png" alt="image-20230711101245141" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-高分辨率训练">2. 高分辨率训练<a href="#2-高分辨率训练" class="hash-link" aria-label="2. 高分辨率训练的直接链接" title="2. 高分辨率训练的直接链接">​</a></h4>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-anchor">3. Anchor<a href="#3-anchor" class="hash-link" aria-label="3. Anchor的直接链接" title="3. Anchor的直接链接">​</a></h4>
<p>YOLOv2引入了anchor机制代替bbox，将图像划分为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>13</mn><mo>×</mo><mn>13</mn></mrow><annotation encoding="application/x-tex">13 \times 13</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">13</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">13</span></span></span></span>个grid cell，每个grid cell生成5个anchor</p>
<p>anchor是通过k-means聚类在数据集上生成的不同尺寸的先验框
对数据集进行anchor宽高比的聚类，聚类数越大，覆盖的IoU越大，但同时模型也更复杂</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="三yolov5">（三）YOLOv5<a href="#三yolov5" class="hash-link" aria-label="（三）YOLOv5的直接链接" title="（三）YOLOv5的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-特征融合">1. 特征融合<a href="#1-特征融合" class="hash-link" aria-label="1. 特征融合的直接链接" title="1. 特征融合的直接链接">​</a></h4>
<p>YOLOv5使用CSPNet实现特征融合，CSP模块由主干和分支构成，主干提取低维特征，分支提取高维特征</p>
<p>主干通过卷积和池化提取特征，形成不同尺寸的特征图</p>
<p>分支将主干输出的特征图作为输入，逐步卷积和上采样提取高级别语义特征</p>
<p>主干特征图通过卷积对通道数降维之后与分支在通道维度上concat</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>在特征提取以及融合阶段可以加入Canny边缘检测得到的特征图进行特征融合</p></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-前处理">2. 前处理<a href="#2-前处理" class="hash-link" aria-label="2. 前处理的直接链接" title="2. 前处理的直接链接">​</a></h4>
<p>对填充黑色像素进行了改善，以填充更少的黑像素 ，提高了精度</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-特征金字塔fcn">3. 特征金字塔FCN<a href="#3-特征金字塔fcn" class="hash-link" aria-label="3. 特征金字塔FCN的直接链接" title="3. 特征金字塔FCN的直接链接">​</a></h4>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="三cbam">三、CBAM<a href="#三cbam" class="hash-link" aria-label="三、CBAM的直接链接" title="三、CBAM的直接链接">​</a></h2>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>提示</div><div class="admonitionContent_BuS1"><p>有关CSP特征融合可以参考：<a href="https://blog.csdn.net/weixin_55073640/article/details/122614176" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/weixin_55073640/article/details/122614176</a></p></div></div>
<p>CBAM是通道+空间注意力机制（SENet是通道注意力机制）</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="一总体结构">（一）总体结构<a href="#一总体结构" class="hash-link" aria-label="（一）总体结构的直接链接" title="（一）总体结构的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/windows_typora/image-20230710234929290.png" alt="image-20230710234929290" class="img_ev3q"></p>
<p>通道注意力：原始特征图<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, c, h, w]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose">]</span></span></span></span>经过通道注意力机制算法得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, c, 1, 1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>的tensor，代表不同通道之间的重要程度，将其与原始特征图相乘</p>
<p>空间注意力：经过通道注意力的特征图<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, c, h, w]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose">]</span></span></span></span>经过空间注意力机制算法得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, 1, h, w]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose">]</span></span></span></span>的tensor，代表宽高维度的像素之间的重要程度，将其与原始特征图相乘</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="二通道注意力">（二）通道注意力<a href="#二通道注意力" class="hash-link" aria-label="（二）通道注意力的直接链接" title="（二）通道注意力的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/windows_typora/image-20230710235658595.png" alt="image-20230710235658595" class="img_ev3q"></p>
<p>原始特征图<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, c, h, w]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose">]</span></span></span></span>分别经过最大池化和平均池化来压缩空间维度、学习通道之间的特征，得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, c, 1, 1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>的tensor，再送入共享的多层感知机网络进行降维再升维，最后将二者相加再经过sigmoid函数产生最终的通道注意力特征图</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="三空间注意力">（三）空间注意力<a href="#三空间注意力" class="hash-link" aria-label="（三）空间注意力的直接链接" title="（三）空间注意力的直接链接">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/windows_typora/image-20230710235603737.png" alt="image-20230710235603737" class="img_ev3q"></p>
<p>原始特征图<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, c, h, w]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose">]</span></span></span></span>分别经过最大池化和平均池化（通过torch.max和torch.mean函数实现）得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, 1, h, w]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose">]</span></span></span></span>的tensor，再将二者concat后通过<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7 \times 7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">7</span></span></span></span>卷积学习特征并降维，最后送入sigmoid函数得到最终的空间注意力特征图</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="四其他注意事项">（四）其他注意事项<a href="#四其他注意事项" class="hash-link" aria-label="（四）其他注意事项的直接链接" title="（四）其他注意事项的直接链接">​</a></h3>
<ol>
<li>作者分别对通道注意力以及空间注意力使用最大池化还是平均池化做了消融实验，结果反映二者都用最大池化以及平均池化再相加效果最好（且对于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7 \times 7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">7</span></span></span></span>卷积与<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span>卷积的消融实验发现，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7</mn><mo>×</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">7 \times 7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">7</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">7</span></span></span></span>卷积效果更好）</li>
<li>作者对先通道注意力还是先空间注意力做了消融实验，结果发现先通道再空间效果更好</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="四focal-loss">四、Focal Loss<a href="#四focal-loss" class="hash-link" aria-label="四、Focal Loss的直接链接" title="四、Focal Loss的直接链接">​</a></h2>
<p>Focal Loss通过引入修正项和样本关注度超参数，增加困难样本的关注度，来解决类别不均衡问题。</p>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora/imagesimage-20230618135151404.png" alt="image-20230618135151404" class="img_ev3q"></p>
<p>YOLO损失函数分为分类损失以及回归损失，可以在分类损失中引入Focal Loss代替原来的交叉熵损失</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="五senet">五、SENet<a href="#五senet" class="hash-link" aria-label="五、SENet的直接链接" title="五、SENet的直接链接">​</a></h2>
<p><img decoding="async" loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/windows_typora/image-20230711091505462.png" alt="image-20230711091505462" class="img_ev3q"></p>
<p>Squeeze and Excitation</p>
<p>Squeeze挤压操作就是将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, c, h, w]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose">]</span></span></span></span>的特征图通过池化挤压宽高维度，得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[b, c, 1, 1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">c</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>的tensor，该tensor还要经过所示的全连接层-ReLU-全连接层结构</p>
<p>Excitation激励操作就是通过sigmoid函数得到每个通道之间的重要程度系数</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="六自注意力机制">六、自注意力机制<a href="#六自注意力机制" class="hash-link" aria-label="六、自注意力机制的直接链接" title="六、自注意力机制的直接链接">​</a></h2>
<p>自注意力机制通过计算元素之间的相似度来确定它们之间的关联性，并对其进行加权处理以获得上下文信息。</p>
<ul>
<li>自注意力机制通过对输入的元素进行<strong>线性变换</strong>来得到<strong>查询（Query）向量</strong>、<strong>键（Key）向量</strong>和<strong>值（Value）向量</strong>。</li>
<li>通过点积和缩放点积计算相似程度</li>
</ul>
<p>通过自注意力机制，每个元素都可以通过与其他元素的相似度计算和加权求和，获取到与它们相关的上下文信息。相似度高的元素将获得更高的权重，因此更受到关注和影响，从而建立起元素之间的关联性。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="七自我介绍">七、自我介绍<a href="#七自我介绍" class="hash-link" aria-label="七、自我介绍的直接链接" title="七、自我介绍的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="一英文自我介绍">（一）英文自我介绍<a href="#一英文自我介绍" class="hash-link" aria-label="（一）英文自我介绍的直接链接" title="（一）英文自我介绍的直接链接">​</a></h3>
<p>This content has been encrypted.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="二西电广研院自我介绍">（二）西电广研院自我介绍<a href="#二西电  广研院自我介绍" class="hash-link" aria-label="（二）西电广研院自我介绍的直接链接" title="（二）西电广研院自我介绍的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-英文自我介绍">1. 英文自我介绍<a href="#1-英文自我介绍" class="hash-link" aria-label="1. 英文自我介绍的直接链接" title="1. 英文自我介绍的直接链接">​</a></h4>
<p>This content has been encrypted.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-中文自我介绍">2. 中文自我介绍<a href="#2-中文自我介绍" class="hash-link" aria-label="2. 中文自我介绍的直接链接" title="2. 中文自我介绍的直接链接">​</a></h4>
<p>This content has been encrypted.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="三电子科技大学自我介绍">（三）电子科技大学自我介绍<a href="#三电子科技大学自我介绍" class="hash-link" aria-label="（三）电子科技大学自我介绍的直接链接" title="（三）电子科技大学自我介绍的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-英文自我介绍-1">1. 英文自我介绍<a href="#1-英文自我介绍-1" class="hash-link" aria-label="1. 英文自我介绍的直接链接" title="1. 英文自我介绍的直接链接">​</a></h4>
<p>This content has been encrypted.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-中文自我介绍-1">2. 中文自我介绍<a href="#2-中文自我介绍-1" class="hash-link" aria-label="2. 中文自我介绍的直接链接" title="2. 中文自我介绍的直接链接">​</a></h4>
<p>This content has been encrypted.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/bonjour-npy/bonjour-npy.github.io/tree/master/docs/Tui-Mian/简历/简历面试准备.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Tui-Mian/机试/大数除法"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">大数除法</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Tui-Mian/计算机基础综合/数据结构"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">数据结构</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#一u-2-net" class="table-of-contents__link toc-highlight">一、U-2-Net</a><ul><li><a href="#一sod任务" class="table-of-contents__link toc-highlight">（一）SOD任务</a></li><li><a href="#二网络结构" class="table-of-contents__link toc-highlight">（二）网络结构</a></li><li><a href="#三损失函数" class="table-of-contents__link toc-highlight">（三）损失函数</a></li><li><a href="#四深度可分离卷积" class="table-of-contents__link toc-highlight">（四）深度可分离卷积</a></li></ul></li><li><a href="#二yolo" class="table-of-contents__link toc-highlight">二、YOLO</a><ul><li><a href="#一map" class="table-of-contents__link toc-highlight">（一）mAP</a></li><li><a href="#二yolov1" class="table-of-contents__link toc-highlight">（二）YOLOv1</a><ul><li><a href="#1预测阶段" class="table-of-contents__link toc-highlight">1.预测阶段</a></li><li><a href="#2-训练过程的损失函数" class="table-of-contents__link toc-highlight">2. 训练过程的损失函数</a></li></ul></li><li><a href="#二yolov2" class="table-of-contents__link toc-highlight">（二）YOLOv2</a><ul><li><a href="#1-bn层" class="table-of-contents__link toc-highlight">1. BN层</a></li><li><a href="#2-高分辨率训练" class="table-of-contents__link toc-highlight">2. 高分辨率训练</a></li><li><a href="#3-anchor" class="table-of-contents__link toc-highlight">3. Anchor</a></li></ul></li><li><a href="#三yolov5" class="table-of-contents__link toc-highlight">（三）YOLOv5</a><ul><li><a href="#1-特征融合" class="table-of-contents__link toc-highlight">1. 特征融合</a></li><li><a href="#2-前处理" class="table-of-contents__link toc-highlight">2. 前处理</a></li><li><a href="#3-特征金字塔fcn" class="table-of-contents__link toc-highlight">3. 特征金字塔FCN</a></li></ul></li></ul></li><li><a href="#三cbam" class="table-of-contents__link toc-highlight">三、CBAM</a><ul><li><a href="#一总体结构" class="table-of-contents__link toc-highlight">（一）总体结构</a></li><li><a href="#二通道注意力" class="table-of-contents__link toc-highlight">（二）通道注意力</a></li><li><a href="#三空间注意力" class="table-of-contents__link toc-highlight">（三）空间注意力</a></li><li><a href="#四其他注意事项" class="table-of-contents__link toc-highlight">（四）其他注意事项</a></li></ul></li><li><a href="#四focal-loss" class="table-of-contents__link toc-highlight">四、Focal Loss</a></li><li><a href="#五senet" class="table-of-contents__link toc-highlight">五、SENet</a></li><li><a href="#六自注意力机制" class="table-of-contents__link toc-highlight">六、自注意力机制</a></li><li><a href="#七自我介绍" class="table-of-contents__link toc-highlight">七、自我介绍</a><ul><li><a href="#一英文自我介绍" class="table-of-contents__link toc-highlight">（一）英文自我介绍</a></li><li><a href="#二西电广研院自我介绍" class="table-of-contents__link toc-highlight">（二）西电广研院自我介绍</a><ul><li><a href="#1-英文自我介绍" class="table-of-contents__link toc-highlight">1. 英文自我介绍</a></li><li><a href="#2-中文自我介绍" class="table-of-contents__link toc-highlight">2. 中文自我介绍</a></li></ul></li><li><a href="#三电子科技大学自我介绍" class="table-of-contents__link toc-highlight">（三）电子科技大学自我介绍</a><ul><li><a href="#1-英文自我介绍-1" class="table-of-contents__link toc-highlight">1. 英文自我介绍</a></li><li><a href="#2-中文自我介绍-1" class="table-of-contents__link toc-highlight">2. 中文自我介绍</a></li></ul></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">👋 联系我</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/WeChat_QR_Code.jpg" target="_blank" rel="noopener noreferrer" class="footer__link-item">WeChat<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.douyin.com/user/self?modal_id=7157246567970360614" target="_blank" rel="noopener noreferrer" class="footer__link-item">TikTok<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">✈️ 外部链接</div><ul class="footer__items clean-list"><li class="footer__item"><a href="http://www.mod.gov.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">共和国国防部<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.xuexi.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">学习强国<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://peacekeeping.un.org/zh" target="_blank" rel="noopener noreferrer" class="footer__link-item">联合国维持和平<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🎅 彩蛋</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.rockstargames.com/gta-v" target="_blank" rel="noopener noreferrer" class="footer__link-item">欢迎来到洛圣都<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.starwars.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">星球大战<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apple.com.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Apple(中国大陆)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🦄 教育官网</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.uestc.edu.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.guet.edu.cn" target="_blank" rel="noopener noreferrer" class="footer__link-item">桂林电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://cfm.uestc.edu.cn/index" target="_blank" rel="noopener noreferrer" class="footer__link-item">未来媒体研究中心<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><br>本网站所展示的标识、链接均属于个人创作和喜好表达，不代表任何国家、政府、企业或组织的官方立场或行为。<br>
                    尽管本网站努力确保信息的准确性和时效性，但所有信息仅供参考，并不构成任何形式的法律、财务或商业建议。<br>
                    <br>Copyright © 2024 bonjour-npy. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>