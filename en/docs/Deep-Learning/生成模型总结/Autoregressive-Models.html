<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Deep-Learning/生成模型总结/Autoregressive-Models" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">图像生成：自回归模型 | 培洋的笔记本📒</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://bonjour-npy.github.io/en/./static/img/intro.png"><meta data-rh="true" name="twitter:image" content="https://bonjour-npy.github.io/en/./static/img/intro.png"><meta data-rh="true" property="og:url" content="https://bonjour-npy.github.io/en/docs/Deep-Learning/生成模型总结/Autoregressive-Models"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="图像生成：自回归模型 | 培洋的笔记本📒"><meta data-rh="true" name="description" content="自回归模型（Autoregressive Models）在图像生成领域扮演着重要角色，它们基于一个核心假设：当前像素值依赖于之前的像素值。这种依赖关系可以通过条件概率来表达，其中每一个像素的生成都是基于之前已经生成的像素的条件分布。在传统的视觉自回归图像生成任务中，这通常意味着从左到右和从上到下的顺序生成每个像素。"><meta data-rh="true" property="og:description" content="自回归模型（Autoregressive Models）在图像生成领域扮演着重要角色，它们基于一个核心假设：当前像素值依赖于之前的像素值。这种依赖关系可以通过条件概率来表达，其中每一个像素的生成都是基于之前已经生成的像素的条件分布。在传统的视觉自回归图像生成任务中，这通常意味着从左到右和从上到下的顺序生成每个像素。"><link data-rh="true" rel="icon" href="/en/img/rockstar-games.svg"><link data-rh="true" rel="canonical" href="https://bonjour-npy.github.io/en/docs/Deep-Learning/生成模型总结/Autoregressive-Models"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/en/docs/Deep-Learning/生成模型总结/Autoregressive-Models" hreflang="en"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Deep-Learning/生成模型总结/Autoregressive-Models" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Deep-Learning/生成模型总结/Autoregressive-Models" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/en/assets/css/styles.8b926d0f.css">
<script src="/en/assets/js/runtime~main.99b0b5c0.js" defer="defer"></script>
<script src="/en/assets/js/main.ead88017.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const a=new URLSearchParams(window.location.search).entries();for(var[t,e]of a)if(t.startsWith("docusaurus-data-")){var n=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(n,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" role="banner"><div class="content_knG7 announcementBarContent_xLdY">✨ 求实求真，大气大为 ✨</div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/navbar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/navbar.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">培洋的笔记本</b></a><a class="navbar__item navbar__link" href="/en/docs/Deep-Learning/intro">🤖 深度学习</a><a class="navbar__item navbar__link" href="/en/docs/GPU-Server/intro">🌍 服务器使用</a><a class="navbar__item navbar__link" href="/en/docs/Tui-Mian/intro">🤡 推免</a><a class="navbar__item navbar__link" href="/en/docs/Algorithms/intro">🎰 算法</a><a class="navbar__item navbar__link" href="/en/docs/Curriculum/intro">📖 课程学习</a><a class="navbar__item navbar__link" href="/en/docs/Others/intro">☃️ 其他</a><a class="navbar__item navbar__link" href="/en/docs/Acknowledgement/intro">🍺 饮水思源</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/docs/Deep-Learning/intro">Welcome</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/docs/Deep-Learning/Fill-The-Gaps">查漏补缺</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/docs/Deep-Learning/基础知识/AlexNet">基础知识</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/docs/Deep-Learning/代码实现/Visdom-Visualization">代码实现</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/docs/Deep-Learning/大模型基础/Self-Attention">大模型基础</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/en/docs/Deep-Learning/生成模型总结/Quick-Notes-about-Main-Techs">生成模型总结</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/生成模型总结/Quick-Notes-about-Main-Techs">主要技术简记</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/生成模型总结/Image-and-Video-Generative-Foundation-Model">图像生成和视频生成基座模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/docs/Deep-Learning/生成模型总结/Autoregressive-Models">图像生成：自回归模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/生成模型总结/Visual-Autoregressive-Modeling-Scalable-Image-Generation-via-Next-Scale-Prediction">自回归模型：VAR</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/生成模型总结/Autoregressive-Model-Beats-Diffusion-Llama-for-Scalable-Image-Generation">自回归模型：LlamaGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/生成模型总结/Autoregressive-Image-Generation-without-Vector-Quantization">自回归模型：MAR</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/生成模型总结/Diffusion-Models">图像生成：扩散模型</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/en/docs/Deep-Learning/论文笔记/Attention-Is-All-You-Need">论文笔记</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">生成模型总结</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">图像生成：自回归模型</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>图像生成：自回归模型</h1></header>
<p>自回归模型（Autoregressive Models）在图像生成领域扮演着重要角色，它们基于一个核心假设：当前像素值依赖于之前的像素值。这种依赖关系可以通过条件概率来表达，其中每一个像素的生成都是基于之前已经生成的像素的条件分布。在传统的视觉自回归图像生成任务中，这通常意味着从左到右和从上到下的顺序生成每个像素。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="自回归模型的数学定义">自回归模型的数学定义<a href="#自回归模型的数学定义" class="hash-link" aria-label="Direct link to 自回归模型的数学定义" title="Direct link to 自回归模型的数学定义">​</a></h2>
<p>自回归（Autoregressive，简称AR）模型是一种统计模型，用于描述时间序 列中的每个值作为其之前值的函数。在机器学习中，自回归模型被广泛应用于序列数据的生成任务，如文本、语音和图像生成。自回归模型通过逐步预测下一个值，依次生成整个序列。</p>
<p>假设有一个序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mrow><mo fence="true">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>T</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">x=\left(x_1, x_2, \ldots, x_T\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">)</span></span></span></span></span> ，自回归模型的目标是学习条件概率分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">p\left(x_t \mid x_{&lt;t}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">)</span></span></span></span></span> ， 即在给定序列前面部分 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo>=</mo><mrow><mo fence="true">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">x_{&lt;t}=\left(x_1, x_2, \ldots, x_{t-1}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6079em;vertical-align:-0.1774em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">)</span></span></span></span></span> 的情况下，预测当前值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 。</p>
<p>对于一个给定的序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span> ，自回归模型的联合概率分布可以分解为以下形式:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>p</mi><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(x)=\prod_{t=1}^T p\left(x_t \mid x_{&lt;t}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">)</span></span></span></span></span></span>
<p>在图像生成任务中，图像被看作是一个二维序列。在传统的自回归图像生成模型（VQVAE、VQGAN 等）将图像的像素视作一个一维序列，通过条件概率分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo fence="true">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo>∣</mo><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">p\left(x_{i, j} \mid x_{&lt;i, j}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">)</span></span></span></span></span> 来生成每个像素值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{i, j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> 。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="autoregressive-模型时间线">Autoregressive 模型时间线<a href="#autoregressive-模型时间线" class="hash-link" aria-label="Direct link to Autoregressive 模型时间线" title="Direct link to Autoregressive 模型时间线">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pixelrnn2016">PixelRNN（2016）<a href="#pixelrnn2016" class="hash-link" aria-label="Direct link to PixelRNN（2016）" title="Direct link to PixelRNN（2016）">​</a></h3>
<p>PixelRNN 是早期的自回归模型之一，它使用循环神经网络（RNN）来建模条件概率分布。由于 RNN 能够捕捉长序列依赖性，PixelRNN 能够生成高质量的图像，但是计算效率较低，因为每次生成一个像素都需要遍历整个序列。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pixelcnn2016">PixelCNN（2016）<a href="#pixelcnn2016" class="hash-link" aria-label="Direct link to PixelCNN（2016）" title="Direct link to PixelCNN（2016）">​</a></h3>
<p>为了克服 PixelRNN 的计算瓶颈，PixelCNN 使用卷积神经网络（CNN）并引入了遮罩技术，确保每个像素仅依赖于其上方和左侧的像素。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vq-vae2017">VQ-VAE（2017）<a href="#vq-vae2017" class="hash-link" aria-label="Direct link to VQ-VAE（2017）" title="Direct link to VQ-VAE（2017）">​</a></h3>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>学习链接</div><div class="admonitionContent_BuS1"><p><a href="https://blog.csdn.net/Je1zvz/article/details/136398797" target="_blank" rel="noopener noreferrer">Variant AutoEncoder(VAE)和 VQVAE 学习笔记和代码</a></p><p><a href="https://www.bilibili.com/video/BV14Y4y1X7wb/?spm_id_from=333.880.my_history.page.click&amp;vd_source=f7612ffc8ec6f523824661106b4c304f" target="_blank" rel="noopener noreferrer">68、VQVAE预训练模型的论文原理及PyTorch代码逐行讲解</a></p></div></div>
<p>在<a href="https://www.spaces.ac.cn/archives/6760" target="_blank" rel="noopener noreferrer">科学空间：VQ-VAE 的简明介绍</a>中，提到了 VQ-VAE 与之前的 PixelCNN 和 PixelRNN 的关系。</p>
<p>受 PixelCNN 和 PixelRNN 专注于像素级的生成的启发，VQ-VAE（Vector Quantized Variational Autoencoder）提出了另一种方法，通过离散的潜在空间来建模数据。VQ-VAE 的主要贡献在于引入了向量量化层，将连续的潜在变量映射到一组离散的嵌入向量上，从而能够更高效地学习复杂的数据分布。</p>
<p><strong>主要思想</strong>：VQ-VAE（Vector Quantized Variational AutoEncoder）通过将连续的图像表示量化为离散的代码来进行图像生成。它引入了一个离散的代码本，将连续的潜在向量映射到离散的代码上，进行编码和解码。</p>
<p><strong>主要贡献</strong>：</p>
<ul>
<li>采用向量量化方法，使得生成模型能够高效地处理离散代码。</li>
<li>在生成模型中，离散化的潜在空间简化了模型的训练和推理过程。</li>
</ul>
<p><strong>与之前模型的关系</strong>：</p>
<ul>
<li>VQ-VAE 在 VAEs（Variational AutoEncoders）的基础上，引入了离散的潜在空间，使得生成效果更好，训练更稳定。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vqvae-22019">VQVAE-2（2019）<a href="#vqvae-22019" class="hash-link" aria-label="Direct link to VQVAE-2（2019）" title="Direct link to VQVAE-2（2019）">​</a></h3>
<p>VQVAE-2 是 VQ-VAE 的一个扩展版本，它引入了层次化的结构，使用多个层次的量化向量来建模不同尺度的特征，从而提高了模型的灵活性和生成图像的质量。</p>
<p><strong>主要思想</strong>：VQ-VAE-2 引入了多层级的离散潜在变量，通过多层级的自回归模型进行生成。它使用了层次化的编码器和解码器结构，更好地捕捉图像中的复杂结构。</p>
<p><strong>主要贡献</strong>：</p>
<ul>
<li>引入了层次化的离散潜在空间，提高了生成图像的质量和分辨率。</li>
<li>在多个层级上进行自回归生成，提高了模型对图像全局和局部信息的捕捉能力。</li>
</ul>
<p><strong>改进点</strong>：</p>
<ul>
<li>相较于 VQ-VAE，VQ-VAE-2 通过层次化的设计，显著提升了生成图像的细节和清晰度。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vqgan2021">VQGAN（2021）<a href="#vqgan2021" class="hash-link" aria-label="Direct link to VQGAN（2021）" title="Direct link to VQGAN（2021）">​</a></h3>
<p>VQGAN 结合了 VQ-VAE 的思想和生成对抗网络（GANs）的优点。它使用编码器和解码器之间的量化瓶颈，并利用 GAN 框架来优化图像质量。VQGAN 在高分辨率图像生成方面表现出了强大的能力。</p>
<p><strong>主要思想</strong>：VQGAN（Vector Quantized Generative Adversarial Networks）结合了 VQ-VAE 的离散潜在表示和 GAN（Generative Adversarial Networks）的对抗训练，提升了生成图像的质量。</p>
<p><strong>主要贡献</strong>：</p>
<ul>
<li>利用对抗训练，生成的图像更加逼真和细腻。</li>
<li>通过结合 VQ-VAE 和 GAN 的优势，解决了各自方法的一些固有缺陷。</li>
</ul>
<p><strong>改进点</strong>：</p>
<ul>
<li>相较于 VQ-VAE-2，VQGAN 通过对抗训练机制，进一步提升了生成图像的视觉质量。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rqtransformer2021">RQTransformer（2021）<a href="#rqtransformer2021" class="hash-link" aria-label="Direct link to RQTransformer（2021）" title="Direct link to RQTransformer（2021）">​</a></h3>
<p>RQTransformer 是一种改进的自回归模型，它利用了自注意力机制，能够有效地处理序列数据。相比于传统的自回归模型，RQTransformer 在大规模数据集上展现了更好的性能，尤其是在自然语言处理和图像生成任务中。</p>
<p><strong>主要思想</strong>：RQ-Transformer（Residual Quantization Transformer）结合了残差量化和 Transformer 架构，通过对潜在空间进行分块量化来提高生成效率和质量。</p>
<p><strong>主要贡献</strong>：</p>
<ul>
<li>引入残差量化方法，提高了潜在空间的表示能力。</li>
<li>结合 Transformer 架构，增强了对复杂图像结构的建模能力。</li>
</ul>
<p><strong>改进点</strong>：</p>
<ul>
<li>相较于 VQ-VAE 和 VQGAN，RQ-Transformer 在潜在空间表示上更为灵活，提高了生成图像的分辨率和质量。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dall-e2021">DALL-E（2021）<a href="#dall-e2021" class="hash-link" aria-label="Direct link to DALL-E（2021）" title="Direct link to DALL-E（2021）">​</a></h3>
<p><strong>主要思想</strong>：DALL-E 是 OpenAI 提出的一个基于 Transformer 的图像生成模型，能够根据文本描述生成图像。它使用了大规模的文本-图像对数据进行训练，并采用了自回归生成策略。其创新之处在于如何将文本和图像模态融合在一起。</p>
<p><strong>主要贡献</strong>：</p>
<ul>
<li>展示了基于文本描述生成图像的强大能力。</li>
<li>引入了大规模数据和 Transformer 架构，使得生成效果更加多样化和逼真。</li>
</ul>
<p><strong>改进点</strong>：</p>
<ul>
<li>相较于之前的图像生成模型，DALL-E 在生成多样性和一致性上有了显著提升，特别是在文本到图像的生成任务中表现出色。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="parti2022">Parti（2022）<a href="#parti2022" class="hash-link" aria-label="Direct link to Parti（2022）" title="Direct link to Parti（2022）">​</a></h3>
<p>Parti 是谷歌研究团队提出的一种模型，专注于分层次的图像生成。它首先生成图像的组成部分（如物体或场景元素），然后将这些部分组合成完整的图像。Parti 在保持图像细节的同时，还能够控制图像的语义内容。</p>
<p><strong>主要思想</strong>：Parti 是一个基于 Transformer 的图像生成模型，能够通过部分图像生成剩余部分。它采用了多阶段生成策略，通过逐步细化生成图像，保证生成效果的一致性和逼真性。</p>
<p><strong>主要贡献</strong>：</p>
<ul>
<li>引入了多阶段的生成策略，提高了生成图像的一致性。</li>
<li>在部分图像生成任务中表现出色，能够根据现有图像生成补全部分。</li>
</ul>
<p><strong>改进点</strong>：</p>
<ul>
<li>相较于 DALL-E 和其他自回归模型，Parti 在生成图像的一致性和细节捕捉上有了显著改进。</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/bonjour-npy/bonjour-npy.github.io/tree/master/docs/Deep-Learning/6-生成模型总结/2-Autoregressive-Models.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/docs/Deep-Learning/生成模型总结/Image-and-Video-Generative-Foundation-Model"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">图像生成和视频生成基座模型</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/docs/Deep-Learning/生成模型总结/Visual-Autoregressive-Modeling-Scalable-Image-Generation-via-Next-Scale-Prediction"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">自回归模型：VAR</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#自回归模型的数学定义" class="table-of-contents__link toc-highlight">自回归模型的数学定义</a></li><li><a href="#autoregressive-模型时间线" class="table-of-contents__link toc-highlight">Autoregressive 模型时间线</a><ul><li><a href="#pixelrnn2016" class="table-of-contents__link toc-highlight">PixelRNN（2016）</a></li><li><a href="#pixelcnn2016" class="table-of-contents__link toc-highlight">PixelCNN（2016）</a></li><li><a href="#vq-vae2017" class="table-of-contents__link toc-highlight">VQ-VAE（2017）</a></li><li><a href="#vqvae-22019" class="table-of-contents__link toc-highlight">VQVAE-2（2019）</a></li><li><a href="#vqgan2021" class="table-of-contents__link toc-highlight">VQGAN（2021）</a></li><li><a href="#rqtransformer2021" class="table-of-contents__link toc-highlight">RQTransformer（2021）</a></li><li><a href="#dall-e2021" class="table-of-contents__link toc-highlight">DALL-E（2021）</a></li><li><a href="#parti2022" class="table-of-contents__link toc-highlight">Parti（2022）</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">👋 联系我</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/WeChat_QR_Code.jpg" target="_blank" rel="noopener noreferrer" class="footer__link-item">WeChat<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.douyin.com/user/self?modal_id=7157246567970360614" target="_blank" rel="noopener noreferrer" class="footer__link-item">TikTok<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">✈️ 外部链接</div><ul class="footer__items clean-list"><li class="footer__item"><a href="http://www.mod.gov.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">共和国国防部<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.xuexi.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">学习强国<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://peacekeeping.un.org/zh" target="_blank" rel="noopener noreferrer" class="footer__link-item">联合国维持和平<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🎅 彩蛋</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.rockstargames.com/gta-v" target="_blank" rel="noopener noreferrer" class="footer__link-item">欢迎来到洛圣都<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.starwars.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">星球大战<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apple.com.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Apple(中国大陆)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🦄 教育官网</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.uestc.edu.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.guet.edu.cn" target="_blank" rel="noopener noreferrer" class="footer__link-item">桂林电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://cfm.uestc.edu.cn/index" target="_blank" rel="noopener noreferrer" class="footer__link-item">未来媒体研究中心<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><br>本网站所展示的标识、链接均属于个人创作和喜好表达，不代表任何国家、政府、企业或组织的官方立场或行为。<br>
                    尽管本网站努力确保信息的准确性和时效性，但所有信息仅供参考，并不构成任何形式的法律、财务或商业建议。<br>
                    <br>Copyright © 2024 bonjour-npy. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>