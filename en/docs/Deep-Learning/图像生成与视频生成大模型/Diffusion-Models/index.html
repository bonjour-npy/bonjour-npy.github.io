<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Deep-Learning/图像生成与视频生成大模型/Diffusion-Models" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">图像生成：扩散模型 | 培洋的笔记本📒</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://bonjour-npy.github.io/en/./static/img/intro.png"><meta data-rh="true" name="twitter:image" content="https://bonjour-npy.github.io/en/./static/img/intro.png"><meta data-rh="true" property="og:url" content="https://bonjour-npy.github.io/en/docs/Deep-Learning/图像生成与视频生成大模型/Diffusion-Models"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="图像生成：扩散模型 | 培洋的笔记本📒"><meta data-rh="true" name="description" content="参考资料："><meta data-rh="true" property="og:description" content="参考资料："><link data-rh="true" rel="icon" href="/en/img/rockstar-games.svg"><link data-rh="true" rel="canonical" href="https://bonjour-npy.github.io/en/docs/Deep-Learning/图像生成与视频生成大模型/Diffusion-Models"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/en/docs/Deep-Learning/图像生成与视频生成大模型/Diffusion-Models" hreflang="en"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Deep-Learning/图像生成与视频生成大模型/Diffusion-Models" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://bonjour-npy.github.io/docs/Deep-Learning/图像生成与视频生成大模型/Diffusion-Models" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/en/assets/css/styles.e09cc62d.css">
<link rel="preload" href="/en/assets/js/runtime~main.82777320.js" as="script">
<link rel="preload" href="/en/assets/js/main.22444c8e.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" role="banner"><div class="content_knG7 announcementBarContent_xLdY">✨ 求实求真，大气大为 ✨</div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/navbar.png" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/en/img/navbar.png" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">培洋的笔记本</b></a><a class="navbar__item navbar__link" href="/en/docs/Deep-Learning/intro">🤖 深度学习</a><a class="navbar__item navbar__link" href="/en/docs/Tui-Mian/intro">🤡 推免</a><a class="navbar__item navbar__link" href="/en/docs/Algorithms/intro">🎰 算法</a><a class="navbar__item navbar__link" href="/en/docs/Curriculum/intro">📖 课程学习</a><a class="navbar__item navbar__link" href="/en/docs/Others/intro">☃️ 其他</a><a class="navbar__item navbar__link" href="/en/docs/Acknowledgement/intro">🍺 饮水思源</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/docs/Deep-Learning/intro">Welcome</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/docs/Deep-Learning/Fill-The-Gaps">查漏补缺</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/en/docs/Deep-Learning/基础知识/AlexNet">基础知识</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/en/docs/Deep-Learning/实战练习/Visdom Visualization">实战练习</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/en/docs/Deep-Learning/大模型基础/Self-Attention">大模型基础</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/en/docs/Deep-Learning/论文笔记/Attention-Is-All-You-Need">论文笔记</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/en/docs/Deep-Learning/图像生成与视频生成大模型/Image-and-Video-Generative-Foundation-Model">图像生成与视频生成大模型</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/图像生成与视频生成大模型/Image-and-Video-Generative-Foundation-Model">图像生成和视频生成基座模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/图像生成与视频生成大模型/Autoregressive-Models">图像生成：自回归模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/图像生成与视频生成大模型/Visual-Autoregressive-Modeling-Scalable-Image-Generation-via-Next-Scale-Prediction">自回归模型：VAR</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/图像生成与视频生成大模型/Autoregressive-Model-Beats-Diffusion-Llama-for-Scalable-Image-Generation">自回归模型：LlamaGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/en/docs/Deep-Learning/图像生成与视频生成大模型/Autoregressive-Image-Generation-without-Vector-Quantization">自回归模型：MAR</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/docs/Deep-Learning/图像生成与视频生成大模型/Diffusion-Models">图像生成：扩散模型</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/en/docs/Deep-Learning/组会记录/1-20240705">组会记录</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">图像生成与视频生成大模型</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">图像生成：扩散模型</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>图像生成：扩散模型</h1><p>参考资料：</p><p><a href="https://cvpr2023-tutorial-diffusion-models.github.io/" target="_blank" rel="noopener noreferrer">CVPR 2023 Tutorial: Denoising Diffusion Models: A Generative Learning Big Bang</a></p><p><a href="https://showlab.github.io/cvpr2024-tutorial-video-diffusion-models/" target="_blank" rel="noopener noreferrer">CVPR 2024 Tutorial: Diffusion-based Video Generative Models</a></p><p><a href="https://www.bilibili.com/video/BV19H4y1G73r/?spm_id_from=333.880.my_history.page.click&amp;vd_source=f7612ffc8ec6f523824661106b4c304f" target="_blank" rel="noopener noreferrer">【较真系列】讲人话-  Diffusion Model 全解（原理+代码+公式）</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="denoising-diffusion-models-在图像中的应用">Denoising Diffusion Models 在图像中的应用<a href="#denoising-diffusion-models-在图像中的应用" class="hash-link" aria-label="Direct link to Denoising Diffusion Models 在图像中的应用" title="Direct link to Denoising Diffusion Models 在图像中的应用">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="diffusion-model-的结构">Diffusion Model 的结构<a href="#diffusion-model-的结构" class="hash-link" aria-label="Direct link to Diffusion Model 的结构" title="Direct link to Diffusion Model 的结构">​</a></h3><ul><li><p>基于 U-Net 结构：被广泛用于 text-to-image Diffusion Model 中</p><ol><li>Imagen</li><li>Stable Diffusion</li><li>eDiff-I</li></ol><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240801095741534.png" alt="image-20240801095741534" class="img_ev3q"></p></li><li><p>基于 Transformer 结构：将图像分割为 patch 后作为 tokens 输入至 Transformer 中</p><ol><li>Scalable Diffusion Models with Transformers</li><li>One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale</li><li>Simple Diffusion: End-to-end Diffusion for High Resolution Images</li></ol><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240801100307093.png" alt="image-20240801100307093" class="img_ev3q"></p></li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="使用-diffusion-model-对图像进行编辑和定制">使用 Diffusion Model 对图像进行编辑和定制<a href="#使用-diffusion-model-对图像进行编辑和定制" class="hash-link" aria-label="Direct link to 使用 Diffusion Model 对图像进行编辑和定制" title="Direct link to 使用 Diffusion Model 对图像进行编辑和定制">​</a></h3><p>目前有三种常见的引导（Guidance）方法：</p><ol><li>RGB Pixel Guidance</li><li>Text Guidance</li><li>Reference Image Guidance</li></ol><h4 class="anchor anchorWithStickyNavbar_LWe7" id="rgb-pixel-guidance">RGB Pixel Guidance<a href="#rgb-pixel-guidance" class="hash-link" aria-label="Direct link to RGB Pixel Guidance" title="Direct link to RGB Pixel Guidance">​</a></h4><h5 class="anchor anchorWithStickyNavbar_LWe7" id="iclr-2022-sdedit-guided-image-synthesis-and-editing-with-stochastic-differential-equations"><a href="https://arxiv.org/abs/2108.01073" target="_blank" rel="noopener noreferrer">ICLR 2022, SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations</a><a href="#iclr-2022-sdedit-guided-image-synthesis-and-editing-with-stochastic-differential-equations" class="hash-link" aria-label="Direct link to iclr-2022-sdedit-guided-image-synthesis-and-editing-with-stochastic-differential-equations" title="Direct link to iclr-2022-sdedit-guided-image-synthesis-and-editing-with-stochastic-differential-equations">​</a></h5><blockquote><p>Given an input image with user guide in a form of manipulating RGB pixels, SDEdit first adds noise to the input, then subsequently denoises the resulting image through the SDE prior to increase its realism.</p></blockquote><p>通过用户在原图上给出一些引导，比如 RGB 像素的涂鸦（stroke painting），甚至可以不给定原图，直接纯手工绘制一个涂鸦画作为输入，模型首先对输入添加噪声，最后通过随机微分方程的先验增加图片的真实性，最终根据输入的带有引导信息的图像生成对应的结果。</p><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240801165223736.png" alt="image-20240801165223736" class="img_ev3q"></p><blockquote><p>Synthesizing images from strokes with SDEdit. The blue dots illustrate the editing process of our method. The green and blue contour plots represent the distributions of images and stroke paintings, respectively. Given a stroke painting, we first perturb it with Gaussian noise and progressively remove the noise by simulating the reverse SDE. This process gradually projects an unrealistic stroke painting to the manifold of natural images.</p></blockquote><p>下图中的蓝点代表本文的编辑过程，绿色分布代表真实图像的分布，蓝色分布代表 stroke paintings 的分布。</p><p>当模型首先被输入 stroke painting 后，使用高斯噪声进行扰动，然后通过模拟反向随机微分方程逐步移除噪声。这一过程逐步将不真实的 stroke painting 投影到自然、真实图像的分布中。</p><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240801163307411.png" alt="image-20240801163307411" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="text-guidance">Text Guidance<a href="#text-guidance" class="hash-link" aria-label="Direct link to Text Guidance" title="Direct link to Text Guidance">​</a></h4><h5 class="anchor anchorWithStickyNavbar_LWe7" id="iclr-2023-diffedit-diffusion-based-semantic-image-editing-with-mask-guidance"><a href="https://arxiv.org/abs/2210.11427" target="_blank" rel="noopener noreferrer">ICLR 2023, DiffEdit: Diffusion-based semantic image editing with mask guidance</a><a href="#iclr-2023-diffedit-diffusion-based-semantic-image-editing-with-mask-guidance" class="hash-link" aria-label="Direct link to iclr-2023-diffedit-diffusion-based-semantic-image-editing-with-mask-guidance" title="Direct link to iclr-2023-diffedit-diffusion-based-semantic-image-editing-with-mask-guidance">​</a></h5><p>论文引入一个掩码生成模块，该模块确定图像的哪一部分应该被编辑，然后只对掩码部分执行基于文本的扩散。</p><p>首先用户输入参考图像以及两个查询文本和参考文本，查询文本 Query 是参考图像的标题或用于描述图像，参考文本 R 用于描述想要替换的效果。</p><p>掩码生成模块首先为输入图像添加噪声，并进行两次去噪，一次通过参考文本 R 进行，一次通过查询文本 Q 进行，并根据去噪结果的差异推导出参考图像中的掩码区域。</p><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240801163117424.png" alt="image-20240801163117424" class="img_ev3q"></p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="cvpr-2023-imagic-text-based-real-image-editing-with-diffusion-models"><a href="https://arxiv.org/abs/2210.09276" target="_blank" rel="noopener noreferrer">CVPR 2023, Imagic: Text-Based Real Image Editing with Diffusion Models</a><a href="#cvpr-2023-imagic-text-based-real-image-editing-with-diffusion-models" class="hash-link" aria-label="Direct link to cvpr-2023-imagic-text-based-real-image-editing-with-diffusion-models" title="Direct link to cvpr-2023-imagic-text-based-real-image-editing-with-diffusion-models">​</a></h5><p>模型接受真实图像（参考图像）和目标文本提示作为输入。</p><ol><li><p>模型首先对目标文本进行编码，得到初始嵌入表示 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>t</mi><mi>g</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{tgt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>，然后优化 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>t</mi><mi>g</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{tgt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 对原始图像进行重构，得到优化后的目标文本嵌入表示 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{opt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span></p></li><li><p>固定优化后的目标文本嵌入表示 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{opt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>​，同时使用 Reconstrcution Loss 对第一步使用的预训练 Diffusion Model 进行微调</p></li><li><p>使用初始目标文本嵌入表示 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>t</mi><mi>g</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{tgt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">g</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span> 插值优化后的目标文本表示 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>o</mi><mi>p</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">e_{opt}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">pt</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></span>，最终通过 fine-tuning 后的 Diffusion Model 生成最终的目标图像</p></li></ol><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesa63ebdaaf7691f50349d43fa374fe69e.png" alt="Imagic 原理描述" class="img_ev3q"></p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="instructpix2pix-learning-to-follow-image-editing-instructions"><a href="https://arxiv.org/pdf/2211.09800" target="_blank" rel="noopener noreferrer">InstructPix2Pix: Learning to Follow Image Editing Instructions</a><a href="#instructpix2pix-learning-to-follow-image-editing-instructions" class="hash-link" aria-label="Direct link to instructpix2pix-learning-to-follow-image-editing-instructions" title="Direct link to instructpix2pix-learning-to-follow-image-editing-instructions">​</a></h5><h6 class="anchor anchorWithStickyNavbar_LWe7" id="主要方法">主要方法<a href="#主要方法" class="hash-link" aria-label="Direct link to 主要方法" title="Direct link to 主要方法">​</a></h6><blockquote><p>Our method consists of two parts: generating an image editing dataset, and training a diffusion model on that dataset. (a) We first use a finetuned GPT-3 to generate instructions and edited captions. (b) We then use StableDiffusion <!-- -->[52]<!-- --> in combination with Prompt-to-Prompt <!-- -->[17]<!-- --> to generate pairs of images from pairs of captions. We use this procedure to create a dataset (c) of over 450,000 training examples. (d) Finally, our InstructPix2Pix diffusion model is trained on our generated data to edit images from instructions. At inference time, our model generalizes to edit real images from human-written instructions.</p></blockquote><p>论文使用现有的 LLMs 工具生成训练数据集，再使用上述生成的数据微调 Stable Diffusion Model，最终得到可以根据指令 caption 进行图像编辑的 Diffusion Model。</p><ol><li><p>训练数据生成阶段：</p><ul><li>首先使用 Input Caption 描述一张图像，并使用 GPT-3 通过指令 Instruction 生成修改过后的图像描述 Edited Caption，如 Input Caption “一张女孩骑在马上的图片”通过指令 Instruction “让她骑在龙上”得到 Edited Caption “一张女孩骑在龙上的图片”</li><li>使用 Stable Diffusion 以及 Prompt2Prompt 通过 Input Caption 以及 Edited Caption 生成一组图像对</li><li>最终得到图像对以及指令 Instruction 组成一组训练数据</li></ul></li><li><p>使用上述训练数据微调 Stable Diffusion：</p><p>首先，对于一张图像 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span></span>，我们将其通过编码器 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">E</mi></mrow><annotation encoding="application/x-tex">\mathcal{E}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathcal" style="margin-right:0.08944em">E</span></span></span></span></span> 转换为对应的潜变量 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mi mathvariant="script">E</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">z=\mathcal{E}(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathcal" style="margin-right:0.08944em">E</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span> 。然后，通过一系列的时间步长 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>∈</mo><mi mathvariant="normal">T</mi></mrow><annotation encoding="application/x-tex">t \in \mathrm{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6542em;vertical-align:-0.0391em"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathrm">T</span></span></span></span></span>，我们将噪声逐步加入到潜变量 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.04398em">z</span></span></span></span></span> 中，得到带有噪声的潜变量 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 。这里的噪声水平随着时间步长的增加而增大。</p><p>接下来，我们训练一个网络 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">\epsilon_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> ，使其能够在给定图像条件 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>I</mi></msub></mrow><annotation encoding="application/x-tex">c_I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 和文本指令条件 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">c_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 的情况下，预测出在当前时间步长 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></span>，<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 所加入的噪声。</p><p>为了达到这一目标，我们需要最小化以下目标函数 Latent Diffusion Objective：</p><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi mathvariant="script">E</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi mathvariant="script">E</mi><mrow><mo fence="true">(</mo><msub><mi>c</mi><mi>I</mi></msub><mo fence="true">)</mo></mrow><mo separator="true">,</mo><msub><mi>c</mi><mi>T</mi></msub><mo separator="true">,</mo><mi>ε</mi><mo>∼</mo><mi>N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>t</mi></mrow></msub><mrow><mo fence="true">[</mo><mi mathvariant="normal">∥</mi><mi>ε</mi><mo>−</mo><msub><mi>ϵ</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>z</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>t</mi><mo separator="true">,</mo><mi mathvariant="script">E</mi><mrow><mo fence="true">(</mo><msub><mi>c</mi><mi>I</mi></msub><mo fence="true">)</mo></mrow><mo separator="true">,</mo><msub><mi>c</mi><mi>T</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><msubsup><mi mathvariant="normal">∥</mi><mn>2</mn><mn>2</mn></msubsup><mo fence="true">]</mo></mrow><annotation encoding="application/x-tex">\left.L=\mathbb{E}_{\mathcal{E}(x), \mathcal{E}\left(c_I\right), c_T, \varepsilon \sim N(0,1), t}\left[\| \varepsilon-\epsilon_\theta\left(z_t, t, \mathcal{E}\left(c_I\right), c_T\right)\right) \|_2^2\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2193em;vertical-align:-0.3552em"></span><span class="minner"><span class="mopen nulldelimiter"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.08944em">E</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span><span class="mpunct mtight">,</span><span class="mord mathcal mtight" style="margin-right:0.08944em">E</span><span class="minner mtight"><span class="mopen mtight delimcenter" style="top:0em"><span class="mtight">(</span></span><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3567em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em"><span></span></span></span></span></span></span><span class="mclose mtight delimcenter" style="top:0em"><span class="mtight">)</span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3567em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">ε</span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">[</span><span class="mord">∥</span><span class="mord mathnormal">ε</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathcal" style="margin-right:0.08944em">E</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">)</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em">)</span></span><span class="mclose delimcenter" style="top:0em">)</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">]</span></span></span></span></span></span></span></div><p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">E</mi></mrow><annotation encoding="application/x-tex">\mathbb{E}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6889em"></span><span class="mord mathbb">E</span></span></span></span></span> 代表数学期望，训练网络 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">\epsilon_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>​​ 使其预测的噪声与真实噪声之间的差距尽可能小，即最小化它们之间的欧几里得距离。</p><blockquote><p>To support image conditioning, we add additional input channels to the first convolutional layer, concatenating <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">E</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>I</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{E}(c_I)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathcal" style="margin-right:0.08944em">E</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>.</p></blockquote><p>为了可以使 Stable Diffusion 支持以图像为条件，作者在第一个卷积层中将 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">z_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span> 与 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">E</mi><mo stretchy="false">(</mo><msub><mi>c</mi><mi>I</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{E}(c_I)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathcal" style="margin-right:0.08944em">E</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em">I</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>​​​ 进行 concat，同时扩充对应网络的 channel 数。</p><p>在微调之前，预训练扩散模型通过 Stable Diffusion v1.5 checkpoint 进行初始化，额外增加通道数的卷积参数都被初始化为 0。</p><h6 class="anchor anchorWithStickyNavbar_LWe7" id="训练设置与参数">训练设置与参数<a href="#训练设置与参数" class="hash-link" aria-label="Direct link to 训练设置与参数" title="Direct link to 训练设置与参数">​</a></h6><p>模型在 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>256</mn><mo>×</mo><mn>256</mn></mrow><annotation encoding="application/x-tex">256 \times 256</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">256</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">256</span></span></span></span></span>​ 分辨率上的 batch size 为 1024，Stable Diffusion 的扩散步数设置为 10, 000，在 8 张 40 GB 显存的 NVIDIA A100 GPU 上训练了 25.5 小时。</p><h6 class="anchor anchorWithStickyNavbar_LWe7" id="推理设置与参数">推理设置与参数<a href="#推理设置与参数" class="hash-link" aria-label="Direct link to 推理设置与参数" title="Direct link to 推理设置与参数">​</a></h6><p>虽然训练过程在 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>256</mn><mo>×</mo><mn>256</mn></mrow><annotation encoding="application/x-tex">256 \times 256</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">256</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">256</span></span></span></span></span> 分辨率上进行，但是在推理阶段直接生成 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>512</mn><mo>×</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">512 \times 512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">512</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">512</span></span></span></span></span> 分辨率的图像效果仍然很好，推理过程扩散步数设置为 100，在 NVIDIA A100 GPU 上推理速度为 9 秒。 </p></li></ol><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240801172101515.png" alt="image-20240801172101515" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="reference-image-guidance">Reference Image Guidance<a href="#reference-image-guidance" class="hash-link" aria-label="Direct link to Reference Image Guidance" title="Direct link to Reference Image Guidance">​</a></h4><h5 class="anchor anchorWithStickyNavbar_LWe7" id="cvpr-2023-dreambooth-fine-tuning-text-to-image-diffusion-models-for-subject-driven-generation"><a href="https://arxiv.org/pdf/2208.12242" target="_blank" rel="noopener noreferrer">CVPR 2023, DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</a><a href="#cvpr-2023-dreambooth-fine-tuning-text-to-image-diffusion-models-for-subject-driven-generation" class="hash-link" aria-label="Direct link to cvpr-2023-dreambooth-fine-tuning-text-to-image-diffusion-models-for-subject-driven-generation" title="Direct link to cvpr-2023-dreambooth-fine-tuning-text-to-image-diffusion-models-for-subject-driven-generation">​</a></h5><p><img loading="lazy" src="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240801185222122.png" alt="image-20240801185222122" class="img_ev3q"></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/bonjour-npy/bonjour-npy.github.io/tree/master/docs/Deep-Learning/7-图像生成与视频生成大模型/6-Diffusion-Models.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/docs/Deep-Learning/图像生成与视频生成大模型/Autoregressive-Image-Generation-without-Vector-Quantization"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">自回归模型：MAR</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/docs/Deep-Learning/组会记录/1-20240705"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">20240705 @ 图像生成与视频生成基座模型</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#denoising-diffusion-models-在图像中的应用" class="table-of-contents__link toc-highlight">Denoising Diffusion Models 在图像中的应用</a><ul><li><a href="#diffusion-model-的结构" class="table-of-contents__link toc-highlight">Diffusion Model 的结构</a></li><li><a href="#使用-diffusion-model-对图像进行编辑和定制" class="table-of-contents__link toc-highlight">使用 Diffusion Model 对图像进行编辑和定制</a><ul><li><a href="#rgb-pixel-guidance" class="table-of-contents__link toc-highlight">RGB Pixel Guidance</a><ul><li><a href="#iclr-2022-sdedit-guided-image-synthesis-and-editing-with-stochastic-differential-equations" class="table-of-contents__link toc-highlight">ICLR 2022, SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations</a></li></ul></li><li><a href="#text-guidance" class="table-of-contents__link toc-highlight">Text Guidance</a><ul><li><a href="#iclr-2023-diffedit-diffusion-based-semantic-image-editing-with-mask-guidance" class="table-of-contents__link toc-highlight">ICLR 2023, DiffEdit: Diffusion-based semantic image editing with mask guidance</a></li><li><a href="#cvpr-2023-imagic-text-based-real-image-editing-with-diffusion-models" class="table-of-contents__link toc-highlight">CVPR 2023, Imagic: Text-Based Real Image Editing with Diffusion Models</a></li><li><a href="#instructpix2pix-learning-to-follow-image-editing-instructions" class="table-of-contents__link toc-highlight">InstructPix2Pix: Learning to Follow Image Editing Instructions</a></li></ul></li><li><a href="#reference-image-guidance" class="table-of-contents__link toc-highlight">Reference Image Guidance</a><ul><li><a href="#cvpr-2023-dreambooth-fine-tuning-text-to-image-diffusion-models-for-subject-driven-generation" class="table-of-contents__link toc-highlight">CVPR 2023, DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation</a></li></ul></li></ul></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">👋 联系我</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/WeChat_QR_Code.jpg" target="_blank" rel="noopener noreferrer" class="footer__link-item">WeChat<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.douyin.com/user/self?modal_id=7157246567970360614" target="_blank" rel="noopener noreferrer" class="footer__link-item">TikTok<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/bonjour-npy" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">✈️ 外部链接</div><ul class="footer__items clean-list"><li class="footer__item"><a href="http://www.mod.gov.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">共和国国防部<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.xuexi.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">学习强国<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://peacekeeping.un.org/zh" target="_blank" rel="noopener noreferrer" class="footer__link-item">联合国维持和平<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🎅 彩蛋</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.rockstargames.com/gta-v" target="_blank" rel="noopener noreferrer" class="footer__link-item">欢迎来到洛圣都<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.starwars.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">星球大战<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.apple.com.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Apple(中国大陆)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">🦄 教育官网</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.uestc.edu.cn/" target="_blank" rel="noopener noreferrer" class="footer__link-item">电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.guet.edu.cn" target="_blank" rel="noopener noreferrer" class="footer__link-item">桂林电子科技大学<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://cfm.uestc.edu.cn/index" target="_blank" rel="noopener noreferrer" class="footer__link-item">未来媒体研究中心<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"><br>本网站所展示的标识、链接均属于个人创作和喜好表达，不代表任何国家、政府、企业或组织的官方立场或行为。<br>
                    尽管本网站努力确保信息的准确性和时效性，但所有信息仅供参考，并不构成任何形式的法律、财务或商业建议。<br>
                    <br>Copyright © 2024 bonjour-npy. Built with Docusaurus.</div></div></div></footer></div>
<script src="/en/assets/js/runtime~main.82777320.js"></script>
<script src="/en/assets/js/main.22444c8e.js"></script>
</body>
</html>