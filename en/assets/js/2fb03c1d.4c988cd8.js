"use strict";(self.webpackChunknpy_notebook=self.webpackChunknpy_notebook||[]).push([[1532],{2970:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>o,toc:()=>d});var r=t(4848),i=t(8453);const s={},a="Speaker Classification",o={id:"Deep-Learning/\u4ee3\u7801\u5b9e\u73b0/Speaker-Classification",title:"Speaker Classification",description:"Transformer\u5b9e\u6218\u7ec3\u4e60\uff0c\u4ee3\u7801\u89c1Github\u4ed3\u5e93\u3002",source:"@site/docs/Deep-Learning/4-\u4ee3\u7801\u5b9e\u73b0/2-Speaker-Classification.md",sourceDirName:"Deep-Learning/4-\u4ee3\u7801\u5b9e\u73b0",slug:"/Deep-Learning/\u4ee3\u7801\u5b9e\u73b0/Speaker-Classification",permalink:"/en/docs/Deep-Learning/\u4ee3\u7801\u5b9e\u73b0/Speaker-Classification",draft:!1,unlisted:!1,editUrl:"https://github.com/bonjour-npy/bonjour-npy.github.io/tree/master/docs/Deep-Learning/4-\u4ee3\u7801\u5b9e\u73b0/2-Speaker-Classification.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{},sidebar:"deep_learning",previous:{title:"Visdom\u53ef\u89c6\u5316",permalink:"/en/docs/Deep-Learning/\u4ee3\u7801\u5b9e\u73b0/Visdom-Visualization"},next:{title:"\u672c\u79d1\u6bd5\u4e1a\u8bba\u6587\uff1a\u57fa\u4e8e Prompt Learning \u7684\u89c6\u89c9-\u8bed\u8a00\u5927\u6a21\u578b\u5728\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u5e94\u7528\u4e0e\u7814\u7a76",permalink:"/en/docs/Deep-Learning/\u4ee3\u7801\u5b9e\u73b0/Undergraduate-Dissertation"}},c={},d=[{value:"Overview",id:"overview",level:2},{value:"Dataset",id:"dataset",level:2},{value:"Related",id:"related",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"speaker-classification",children:"Speaker Classification"})}),"\n",(0,r.jsxs)(n.admonition,{title:"\u5b9e\u6218\u7ec3\u4e60",type:"tip",children:[(0,r.jsxs)(n.p,{children:["Transformer\u5b9e\u6218\u7ec3\u4e60\uff0c\u4ee3\u7801\u89c1",(0,r.jsx)(n.a,{href:"https://github.com/bonjour-npy/Speaker-Classification",children:"Github\u4ed3\u5e93"}),"\u3002"]}),(0,r.jsxs)(n.p,{children:["This is a practice of Transformer, follow the guide of ",(0,r.jsx)(n.a,{href:"https://github.com/bonjour-npy/Speaker-Classification",children:"Github Repo"}),"."]})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesimage-20240113175506430.png",alt:"image-20240113175506430"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Classify the speaker of given features, learn how to use Transformer and how to adjust parameters of transformer."}),"\n",(0,r.jsx)(n.h2,{id:"dataset",children:"Dataset"}),"\n",(0,r.jsxs)(n.p,{children:["The original dataset is ",(0,r.jsx)(n.a,{href:"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/",children:"VoxCeleb1"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["We randomly select 600 speakers from ",(0,r.jsx)(n.a,{href:"https://www.robots.ox.ac.uk/~vgg/data/voxceleb/",children:"VoxCeleb1"}),", then preprocess the raw waveforms into mel-spectrograms. You can download the preprocessed dataset from ",(0,r.jsx)(n.a,{href:"https://drive.google.com/file/d/1gaFy8RaQVUEXo2n0peCBR5gYKCB-mNHc/view?usp=drive_link",children:"Google Drive"}),"."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://raw.githubusercontent.com/bonjour-npy/Image-Hosting-Service/main/typora_imagesScreenshot%202024-01-13%20163041.png",alt:"Screenshot 2024-01-13 163041"})}),"\n",(0,r.jsx)(n.p,{children:"Arguments:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"data_dir: The path to the data directory."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"metadata_path: The path to the metadata."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"segment_len: The length of audio segment for training."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The architecture of dataset directory is shown below, where ",(0,r.jsx)(n.code,{children:"uttr-{random string}.pt"})," represents PyTorch data file containing ",(0,r.jsx)(n.code,{children:"valid mel-spectrogram data"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"data directory/\n\u251c\u2500\u2500 mapping.json\n\u251c\u2500\u2500 metadata.json\n\u251c\u2500\u2500 testdata.json\n\u2514\u2500\u2500 uttr-{random string}.pt\n"})}),"\n",(0,r.jsx)(n.h2,{id:"related",children:"Related"}),"\n",(0,r.jsxs)(n.p,{children:["This is also the assignment solution of ",(0,r.jsx)(n.a,{href:"https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php",children:"ML2021Spring HW4"}),"."]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var r=t(6540);const i={},s=r.createContext(i);function a(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);